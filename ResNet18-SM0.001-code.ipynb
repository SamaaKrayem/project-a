{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3be3ec6d07444c938cef97e0b5e32db0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d99ee01f1dea484fb0aa202f2e0d1ea4",
              "IPY_MODEL_3ba03490f27549d7bd0172869b5733cc",
              "IPY_MODEL_09c1ff5645d543b58d831146bc3c211d"
            ],
            "layout": "IPY_MODEL_9b8f6a012b014882a2326f78750b057a"
          }
        },
        "d99ee01f1dea484fb0aa202f2e0d1ea4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17e57b9fd4e74ac5abc5f38db3ea96ec",
            "placeholder": "​",
            "style": "IPY_MODEL_0ad1450447ec4b4fa8642d67ffbe987a",
            "value": "100%"
          }
        },
        "3ba03490f27549d7bd0172869b5733cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a25e1800d7eb4b9196919abae3e1ab5f",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_13b804a3113d47b9babf6a4a322a6fd8",
            "value": 170498071
          }
        },
        "09c1ff5645d543b58d831146bc3c211d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd440c0535c84c139ec8cfb8e7c60bca",
            "placeholder": "​",
            "style": "IPY_MODEL_92157240e4ac4fd9b4e0e9cd0ddecbf8",
            "value": " 170498071/170498071 [00:05&lt;00:00, 33575921.20it/s]"
          }
        },
        "9b8f6a012b014882a2326f78750b057a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17e57b9fd4e74ac5abc5f38db3ea96ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ad1450447ec4b4fa8642d67ffbe987a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a25e1800d7eb4b9196919abae3e1ab5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13b804a3113d47b9babf6a4a322a6fd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dd440c0535c84c139ec8cfb8e7c60bca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92157240e4ac4fd9b4e0e9cd0ddecbf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DIPoz_U_N7H_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import warnings\n",
        "from typing import Optional, Tuple\n",
        "\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.nn.init import constant_, xavier_normal_, xavier_uniform_\n",
        "from torch.nn.parameter import Parameter\n",
        "import torch.autograd\n",
        "from torch import autograd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sm_alpha=0.001"
      ],
      "metadata": {
        "id": "p_clPsv5pq0R"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def SMrelu_forward(z: Tensor, alpha: float):\n",
        "    relu_positive = z\n",
        "    relu_zero = 0\n",
        "    relu_output = torch.where(z>0, relu_positive, relu_zero)\n",
        "    return relu_output\n",
        "  "
      ],
      "metadata": {
        "id": "CvNU8Y17YmAK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SMRELUFunction(torch.autograd.Function):\n",
        "    \n",
        "    @staticmethod\n",
        "    def forward(ctx, z: Tensor, alpha: float):\n",
        "        relu = SMrelu_forward(z, alpha) # Regular forward pass computation from before\n",
        "        ctx.save_for_backward(z)    # Tensors should be saved using this method\n",
        "        ctx.alpha = alpha           # other properties can be saved like so\n",
        "        return relu\n",
        "    \n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        z, = ctx.saved_tensors      # Validates that no in-place modifications happened on saved tensors\n",
        "        alpha = ctx.alpha\n",
        "        \n",
        "        # Calculate diagonal of d(elu(z))/dz\n",
        "        grad_positive = torch.ones_like(z)\n",
        "        grad_zero = 0\n",
        "        \n",
        "        # Note: This is not the full Jacobian, d(elu(z))/dz, it's the diagonal\n",
        "        grad_SMrelu = torch.where(z > ((-1)*alpha), grad_positive, grad_zero)\n",
        "        \n",
        "        # Gradient of the loss w.r.t. our output\n",
        "        δ_smrelu = grad_output\n",
        "        \n",
        "        # Calcualte δz = d(elu(z))/dz * δ_elu\n",
        "        # Note: elementwise multiplication equivalant to vector-Jacobian product\n",
        "        δz = grad_SMrelu * δ_smrelu\n",
        "        return δz, None"
      ],
      "metadata": {
        "id": "CUE6bnaQYoci"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = SMRELUFunction.apply(self.bn1(self.conv1(x)),sm_alpha)\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = SMRELUFunction.apply(out,sm_alpha)\n",
        "        return out"
      ],
      "metadata": {
        "id": "JG87HJtWOq4F"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
        "                               planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = SMRELUFunction.apply(self.bn1(self.conv1(x)),sm_alpha)\n",
        "        out = SMRELUFunction.apply(self.bn2(self.conv2(out)),sm_alpha)\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = SMRELUFunction.apply(out,sm_alpha)\n",
        "        return out"
      ],
      "metadata": {
        "id": "eH0PTSE9O6ex"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = SMRELUFunction.apply(self.bn1(self.conv1(x)),sm_alpha)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "K8pFz-yZPJLV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
        "\n",
        "\n",
        "def ResNet34():\n",
        "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
        "\n",
        "\n",
        "def ResNet50():\n",
        "    return ResNet(Bottleneck, [3, 4, 6, 3])\n",
        "\n",
        "\n",
        "def ResNet101():\n",
        "    return ResNet(Bottleneck, [3, 4, 23, 3])\n",
        "\n",
        "\n",
        "def ResNet152():\n",
        "    return ResNet(Bottleneck, [3, 8, 36, 3])\n",
        "\n",
        "\n",
        "def test():\n",
        "    net = ResNet18()\n",
        "    y = net(torch.randn(1, 3, 32, 32))\n",
        "    print(y.size())"
      ],
      "metadata": {
        "id": "yDQjwYW7PPzG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "\n",
        "TOTAL_BAR_LENGTH=65\n",
        "_, term_width = shutil.get_terminal_size()\n",
        "term_width = int(term_width)\n",
        "last_time = time.time()\n",
        "begin_time = last_time\n",
        "\n",
        "def format_time(seconds):\n",
        "    days = int(seconds / 3600/24)\n",
        "    seconds = seconds - days*3600*24\n",
        "    hours = int(seconds / 3600)\n",
        "    seconds = seconds - hours*3600\n",
        "    minutes = int(seconds / 60)\n",
        "    seconds = seconds - minutes*60\n",
        "    secondsf = int(seconds)\n",
        "    seconds = seconds - secondsf\n",
        "    millis = int(seconds*1000)\n",
        "\n",
        "    f = ''\n",
        "    i = 1\n",
        "    if days > 0:\n",
        "        f += str(days) + 'D'\n",
        "        i += 1\n",
        "    if hours > 0 and i <= 2:\n",
        "        f += str(hours) + 'h'\n",
        "        i += 1\n",
        "    if minutes > 0 and i <= 2:\n",
        "        f += str(minutes) + 'm'\n",
        "        i += 1\n",
        "    if secondsf > 0 and i <= 2:\n",
        "        f += str(secondsf) + 's'\n",
        "        i += 1\n",
        "    if millis > 0 and i <= 2:\n",
        "        f += str(millis) + 'ms'\n",
        "        i += 1\n",
        "    if f == '':\n",
        "        f = '0ms'\n",
        "    return f\n",
        "\n",
        "def progress_bar(current, total, msg=None):\n",
        "    global last_time, begin_time\n",
        "    if current == 0:\n",
        "        begin_time = time.time()  # Reset for new bar.\n",
        "\n",
        "    cur_len = int(TOTAL_BAR_LENGTH*current/total)\n",
        "    rest_len = int(TOTAL_BAR_LENGTH - cur_len) - 1\n",
        "\n",
        "    sys.stdout.write(' [')\n",
        "    for i in range(cur_len):\n",
        "        sys.stdout.write('=')\n",
        "    sys.stdout.write('>')\n",
        "    for i in range(rest_len):\n",
        "        sys.stdout.write('.')\n",
        "    sys.stdout.write(']')\n",
        "\n",
        "    cur_time = time.time()\n",
        "    step_time = cur_time - last_time\n",
        "    last_time = cur_time\n",
        "    tot_time = cur_time - begin_time\n",
        "\n",
        "    L = []\n",
        "    L.append('  Step: %s' % format_time(step_time))\n",
        "    L.append(' | Tot: %s' % format_time(tot_time))\n",
        "    if msg:\n",
        "        L.append(' | ' + msg)\n",
        "\n",
        "    msg = ''.join(L)\n",
        "    sys.stdout.write(msg)\n",
        "    for i in range(term_width-int(TOTAL_BAR_LENGTH)-len(msg)-3):\n",
        "        sys.stdout.write(' ')\n",
        "\n",
        "    # Go back to the center of the bar.\n",
        "    for i in range(term_width-int(TOTAL_BAR_LENGTH/2)+2):\n",
        "        sys.stdout.write('\\b')\n",
        "    sys.stdout.write(' %d/%d ' % (current+1, total))\n",
        "\n",
        "    if current < total-1:\n",
        "        sys.stdout.write('\\r')\n",
        "    else:\n",
        "        sys.stdout.write('\\n')\n",
        "    sys.stdout.flush()"
      ],
      "metadata": {
        "id": "pPvEMIItPT5I"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import argparse"
      ],
      "metadata": {
        "id": "wcFx4bzgPcgK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parser = argparse.ArgumentParser(description='PyTorch CIFAR10 Training')\n",
        "parser.add_argument('-f')\n",
        "parser.add_argument('--lr', default=0.1, type=float, help='learning rate')\n",
        "parser.add_argument('--resume', '-r', action='store_true',\n",
        "                    help='resume from checkpoint')\n",
        "args = parser.parse_args()\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "best_acc = 0  # best test accuracy\n",
        "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
        "\n",
        "# Data\n",
        "print('==> Preparing data..')\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122,
          "referenced_widgets": [
            "3be3ec6d07444c938cef97e0b5e32db0",
            "d99ee01f1dea484fb0aa202f2e0d1ea4",
            "3ba03490f27549d7bd0172869b5733cc",
            "09c1ff5645d543b58d831146bc3c211d",
            "9b8f6a012b014882a2326f78750b057a",
            "17e57b9fd4e74ac5abc5f38db3ea96ec",
            "0ad1450447ec4b4fa8642d67ffbe987a",
            "a25e1800d7eb4b9196919abae3e1ab5f",
            "13b804a3113d47b9babf6a4a322a6fd8",
            "dd440c0535c84c139ec8cfb8e7c60bca",
            "92157240e4ac4fd9b4e0e9cd0ddecbf8"
          ]
        },
        "id": "TRBFd30YPh1y",
        "outputId": "00814992-b1a7-4c6c-dcf1-08404415d3ed"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Preparing data..\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3be3ec6d07444c938cef97e0b5e32db0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('==> Building model..')\n",
        "net = ResNet18()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqUaN13mPnPW",
        "outputId": "f81bbe70-a68e-4dd7-e759-22215cb5761f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Building model..\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = net.to(device)\n",
        "if device == 'cuda':\n",
        "    net = torch.nn.DataParallel(net)\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "if args.resume:\n",
        "    # Load checkpoint.\n",
        "    print('==> Resuming from checkpoint..')\n",
        "    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n",
        "    checkpoint = torch.load('./checkpoint/ckpt.pth')\n",
        "    net.load_state_dict(checkpoint['net'])\n",
        "    best_acc = checkpoint['acc']\n",
        "    start_epoch = checkpoint['epoch']\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=args.lr,\n",
        "                      momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)"
      ],
      "metadata": {
        "id": "8g3PFt4iPqMd"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "def train(epoch):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "        progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "                     % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n"
      ],
      "metadata": {
        "id": "68AwBErQPxyB"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(epoch):\n",
        "    global best_acc\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "                         % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "\n",
        "    # Save checkpoint.\n",
        "    acc = 100.*correct/total\n",
        "    if acc > best_acc:\n",
        "        print('Saving..')\n",
        "        state = {\n",
        "            'net': net.state_dict(),\n",
        "            'acc': acc,\n",
        "            'epoch': epoch,\n",
        "        }\n",
        "        if not os.path.isdir('checkpoint'):\n",
        "            os.mkdir('checkpoint')\n",
        "        torch.save(state, './checkpoint/ckpt.pth')\n",
        "        best_acc = acc\n"
      ],
      "metadata": {
        "id": "jhQa5SEbP4Ys"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(start_epoch, start_epoch+150):\n",
        "    train(epoch)\n",
        "    test(epoch)\n",
        "    scheduler.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9g4sAqPP_rS",
        "outputId": "d5b0083c-e1dd-4694-ac06-449ae6d31f94"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 0\n",
            " [================================================================>]  Step: 567ms | Tot: 45s869ms | Loss: 1.779 | Acc: 35.416% (17708/50000) 391/391 \n",
            " [================================================================>]  Step: 39ms | Tot: 4s185ms | Loss: 1.459 | Acc: 45.620% (4562/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 1\n",
            " [================================================================>]  Step: 95ms | Tot: 46s786ms | Loss: 1.278 | Acc: 53.766% (26883/50000) 391/391 \n",
            " [================================================================>]  Step: 41ms | Tot: 4s288ms | Loss: 1.114 | Acc: 59.930% (5993/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 2\n",
            " [================================================================>]  Step: 85ms | Tot: 46s847ms | Loss: 1.006 | Acc: 64.490% (32245/50000) 391/391 \n",
            " [================================================================>]  Step: 44ms | Tot: 4s347ms | Loss: 1.073 | Acc: 62.890% (6289/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 3\n",
            " [================================================================>]  Step: 78ms | Tot: 46s864ms | Loss: 0.830 | Acc: 70.814% (35407/50000) 391/391 \n",
            " [================================================================>]  Step: 40ms | Tot: 4s88ms | Loss: 0.749 | Acc: 73.710% (7371/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 4\n",
            " [================================================================>]  Step: 77ms | Tot: 46s455ms | Loss: 0.703 | Acc: 75.384% (37692/50000) 391/391 \n",
            " [================================================================>]  Step: 39ms | Tot: 5s76ms | Loss: 0.711 | Acc: 74.910% (7491/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 5\n",
            " [================================================================>]  Step: 80ms | Tot: 46s521ms | Loss: 0.621 | Acc: 78.480% (39240/50000) 391/391 \n",
            " [================================================================>]  Step: 36ms | Tot: 5s152ms | Loss: 0.711 | Acc: 75.920% (7592/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 6\n",
            " [================================================================>]  Step: 78ms | Tot: 46s273ms | Loss: 0.569 | Acc: 80.328% (40164/50000) 391/391 \n",
            " [================================================================>]  Step: 47ms | Tot: 4s338ms | Loss: 0.673 | Acc: 77.250% (7725/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 7\n",
            " [================================================================>]  Step: 74ms | Tot: 46s612ms | Loss: 0.536 | Acc: 81.570% (40785/50000) 391/391 \n",
            " [================================================================>]  Step: 45ms | Tot: 4s225ms | Loss: 0.671 | Acc: 77.860% (7786/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 8\n",
            " [================================================================>]  Step: 81ms | Tot: 46s733ms | Loss: 0.507 | Acc: 82.662% (41331/50000) 391/391 \n",
            " [================================================================>]  Step: 39ms | Tot: 4s257ms | Loss: 0.576 | Acc: 80.370% (8037/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 9\n",
            " [================================================================>]  Step: 71ms | Tot: 46s588ms | Loss: 0.489 | Acc: 83.274% (41637/50000) 391/391 \n",
            " [================================================================>]  Step: 47ms | Tot: 4s194ms | Loss: 0.723 | Acc: 76.890% (7689/10000) 100/100 \n",
            "\n",
            "Epoch: 10\n",
            " [================================================================>]  Step: 81ms | Tot: 46s626ms | Loss: 0.464 | Acc: 84.016% (42008/50000) 391/391 \n",
            " [================================================================>]  Step: 45ms | Tot: 4s198ms | Loss: 0.535 | Acc: 81.690% (8169/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 11\n",
            " [================================================================>]  Step: 78ms | Tot: 46s682ms | Loss: 0.459 | Acc: 84.118% (42059/50000) 391/391 \n",
            " [================================================================>]  Step: 40ms | Tot: 4s225ms | Loss: 0.626 | Acc: 79.950% (7995/10000) 100/100 \n",
            "\n",
            "Epoch: 12\n",
            " [================================================================>]  Step: 83ms | Tot: 46s757ms | Loss: 0.444 | Acc: 84.722% (42361/50000) 391/391 \n",
            " [================================================================>]  Step: 41ms | Tot: 4s204ms | Loss: 0.614 | Acc: 79.080% (7908/10000) 100/100 \n",
            "\n",
            "Epoch: 13\n",
            " [================================================================>]  Step: 82ms | Tot: 46s406ms | Loss: 0.431 | Acc: 85.272% (42636/50000) 391/391 \n",
            " [================================================================>]  Step: 30ms | Tot: 4s248ms | Loss: 0.779 | Acc: 75.080% (7508/10000) 100/100 \n",
            "\n",
            "Epoch: 14\n",
            " [================================================================>]  Step: 83ms | Tot: 46s538ms | Loss: 0.423 | Acc: 85.480% (42740/50000) 391/391 \n",
            " [================================================================>]  Step: 47ms | Tot: 4s142ms | Loss: 0.527 | Acc: 82.240% (8224/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 15\n",
            " [================================================================>]  Step: 87ms | Tot: 46s631ms | Loss: 0.410 | Acc: 86.046% (43023/50000) 391/391 \n",
            " [================================================================>]  Step: 42ms | Tot: 4s240ms | Loss: 0.519 | Acc: 82.060% (8206/10000) 100/100 \n",
            "\n",
            "Epoch: 16\n",
            " [================================================================>]  Step: 82ms | Tot: 46s446ms | Loss: 0.402 | Acc: 86.202% (43101/50000) 391/391 \n",
            " [================================================================>]  Step: 48ms | Tot: 4s252ms | Loss: 0.549 | Acc: 81.540% (8154/10000) 100/100 \n",
            "\n",
            "Epoch: 17\n",
            " [================================================================>]  Step: 84ms | Tot: 46s618ms | Loss: 0.394 | Acc: 86.498% (43249/50000) 391/391 \n",
            " [================================================================>]  Step: 35ms | Tot: 4s185ms | Loss: 0.618 | Acc: 80.020% (8002/10000) 100/100 \n",
            "\n",
            "Epoch: 18\n",
            " [================================================================>]  Step: 83ms | Tot: 46s570ms | Loss: 0.397 | Acc: 86.478% (43239/50000) 391/391 \n",
            " [================================================================>]  Step: 41ms | Tot: 4s70ms | Loss: 0.476 | Acc: 83.880% (8388/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 19\n",
            " [================================================================>]  Step: 85ms | Tot: 46s582ms | Loss: 0.386 | Acc: 86.722% (43361/50000) 391/391 \n",
            " [================================================================>]  Step: 42ms | Tot: 4s206ms | Loss: 0.463 | Acc: 84.100% (8410/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 20\n",
            " [================================================================>]  Step: 84ms | Tot: 46s366ms | Loss: 0.382 | Acc: 86.968% (43484/50000) 391/391 \n",
            " [================================================================>]  Step: 31ms | Tot: 5s10ms | Loss: 0.490 | Acc: 83.450% (8345/10000) 100/100 \n",
            "\n",
            "Epoch: 21\n",
            " [================================================================>]  Step: 72ms | Tot: 46s400ms | Loss: 0.372 | Acc: 87.172% (43586/50000) 391/391 \n",
            " [================================================================>]  Step: 37ms | Tot: 4s129ms | Loss: 0.510 | Acc: 83.000% (8300/10000) 100/100 \n",
            "\n",
            "Epoch: 22\n",
            " [================================================================>]  Step: 75ms | Tot: 46s513ms | Loss: 0.368 | Acc: 87.530% (43765/50000) 391/391 \n",
            " [================================================================>]  Step: 26ms | Tot: 4s211ms | Loss: 0.544 | Acc: 82.150% (8215/10000) 100/100 \n",
            "\n",
            "Epoch: 23\n",
            " [================================================================>]  Step: 91ms | Tot: 46s443ms | Loss: 0.365 | Acc: 87.650% (43825/50000) 391/391 \n",
            " [================================================================>]  Step: 39ms | Tot: 4s218ms | Loss: 0.480 | Acc: 84.200% (8420/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 24\n",
            " [================================================================>]  Step: 90ms | Tot: 46s506ms | Loss: 0.360 | Acc: 87.610% (43805/50000) 391/391 \n",
            " [================================================================>]  Step: 38ms | Tot: 4s121ms | Loss: 0.471 | Acc: 84.480% (8448/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 25\n",
            " [================================================================>]  Step: 84ms | Tot: 46s649ms | Loss: 0.358 | Acc: 87.724% (43862/50000) 391/391 \n",
            " [================================================================>]  Step: 48ms | Tot: 4s136ms | Loss: 0.539 | Acc: 82.610% (8261/10000) 100/100 \n",
            "\n",
            "Epoch: 26\n",
            " [================================================================>]  Step: 95ms | Tot: 46s252ms | Loss: 0.354 | Acc: 87.918% (43959/50000) 391/391 \n",
            " [================================================================>]  Step: 47ms | Tot: 4s176ms | Loss: 0.576 | Acc: 81.230% (8123/10000) 100/100 \n",
            "\n",
            "Epoch: 27\n",
            " [================================================================>]  Step: 73ms | Tot: 46s514ms | Loss: 0.351 | Acc: 88.064% (44032/50000) 391/391 \n",
            " [================================================================>]  Step: 43ms | Tot: 4s83ms | Loss: 0.464 | Acc: 84.380% (8438/10000) 100/100 \n",
            "\n",
            "Epoch: 28\n",
            " [================================================================>]  Step: 71ms | Tot: 46s461ms | Loss: 0.350 | Acc: 88.022% (44011/50000) 391/391 \n",
            " [================================================================>]  Step: 27ms | Tot: 4s184ms | Loss: 0.670 | Acc: 79.760% (7976/10000) 100/100 \n",
            "\n",
            "Epoch: 29\n",
            " [================================================================>]  Step: 79ms | Tot: 46s623ms | Loss: 0.346 | Acc: 88.120% (44060/50000) 391/391 \n",
            " [================================================================>]  Step: 36ms | Tot: 4s159ms | Loss: 0.553 | Acc: 82.030% (8203/10000) 100/100 \n",
            "\n",
            "Epoch: 30\n",
            " [================================================================>]  Step: 77ms | Tot: 46s374ms | Loss: 0.346 | Acc: 88.138% (44069/50000) 391/391 \n",
            " [================================================================>]  Step: 39ms | Tot: 4s210ms | Loss: 0.478 | Acc: 84.100% (8410/10000) 100/100 \n",
            "\n",
            "Epoch: 31\n",
            " [================================================================>]  Step: 82ms | Tot: 46s270ms | Loss: 0.342 | Acc: 88.504% (44252/50000) 391/391 \n",
            " [================================================================>]  Step: 40ms | Tot: 4s332ms | Loss: 0.563 | Acc: 81.310% (8131/10000) 100/100 \n",
            "\n",
            "Epoch: 32\n",
            " [================================================================>]  Step: 82ms | Tot: 45s990ms | Loss: 0.332 | Acc: 88.768% (44384/50000) 391/391 \n",
            " [================================================================>]  Step: 26ms | Tot: 4s420ms | Loss: 0.492 | Acc: 84.190% (8419/10000) 100/100 \n",
            "\n",
            "Epoch: 33\n",
            " [================================================================>]  Step: 74ms | Tot: 46s90ms | Loss: 0.336 | Acc: 88.560% (44280/50000) 391/391 \n",
            " [================================================================>]  Step: 33ms | Tot: 4s132ms | Loss: 0.481 | Acc: 83.720% (8372/10000) 100/100 \n",
            "\n",
            "Epoch: 34\n",
            " [================================================================>]  Step: 81ms | Tot: 46s6ms | Loss: 0.334 | Acc: 88.706% (44353/50000) 391/391 \n",
            " [================================================================>]  Step: 42ms | Tot: 4s88ms | Loss: 0.481 | Acc: 83.930% (8393/10000) 100/100 \n",
            "\n",
            "Epoch: 35\n",
            " [================================================================>]  Step: 71ms | Tot: 46s290ms | Loss: 0.326 | Acc: 88.770% (44385/50000) 391/391 \n",
            " [================================================================>]  Step: 38ms | Tot: 4s64ms | Loss: 0.395 | Acc: 86.630% (8663/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 36\n",
            " [================================================================>]  Step: 83ms | Tot: 46s280ms | Loss: 0.326 | Acc: 88.896% (44448/50000) 391/391 \n",
            " [================================================================>]  Step: 30ms | Tot: 3s974ms | Loss: 0.921 | Acc: 74.810% (7481/10000) 100/100 \n",
            "\n",
            "Epoch: 37\n",
            " [================================================================>]  Step: 77ms | Tot: 46s477ms | Loss: 0.323 | Acc: 88.950% (44475/50000) 391/391 \n",
            " [================================================================>]  Step: 30ms | Tot: 4s111ms | Loss: 0.579 | Acc: 81.630% (8163/10000) 100/100 \n",
            "\n",
            "Epoch: 38\n",
            " [================================================================>]  Step: 79ms | Tot: 46s551ms | Loss: 0.320 | Acc: 89.186% (44593/50000) 391/391 \n",
            " [================================================================>]  Step: 39ms | Tot: 3s983ms | Loss: 0.609 | Acc: 80.580% (8058/10000) 100/100 \n",
            "\n",
            "Epoch: 39\n",
            " [================================================================>]  Step: 82ms | Tot: 46s245ms | Loss: 0.318 | Acc: 89.292% (44646/50000) 391/391 \n",
            " [================================================================>]  Step: 42ms | Tot: 4s154ms | Loss: 0.459 | Acc: 84.850% (8485/10000) 100/100 \n",
            "\n",
            "Epoch: 40\n",
            " [================================================================>]  Step: 81ms | Tot: 46s329ms | Loss: 0.315 | Acc: 89.358% (44679/50000) 391/391 \n",
            " [================================================================>]  Step: 48ms | Tot: 3s996ms | Loss: 0.471 | Acc: 84.290% (8429/10000) 100/100 \n",
            "\n",
            "Epoch: 41\n",
            " [================================================================>]  Step: 85ms | Tot: 46s128ms | Loss: 0.316 | Acc: 89.028% (44514/50000) 391/391 \n",
            " [================================================================>]  Step: 52ms | Tot: 4s885ms | Loss: 0.425 | Acc: 85.940% (8594/10000) 100/100 \n",
            "\n",
            "Epoch: 42\n",
            " [================================================================>]  Step: 86ms | Tot: 46s51ms | Loss: 0.314 | Acc: 89.290% (44645/50000) 391/391 \n",
            " [================================================================>]  Step: 31ms | Tot: 4s35ms | Loss: 0.403 | Acc: 86.520% (8652/10000) 100/100 \n",
            "\n",
            "Epoch: 43\n",
            " [================================================================>]  Step: 84ms | Tot: 46s373ms | Loss: 0.312 | Acc: 89.278% (44639/50000) 391/391 \n",
            " [================================================================>]  Step: 38ms | Tot: 4s6ms | Loss: 0.471 | Acc: 83.820% (8382/10000) 100/100 \n",
            "\n",
            "Epoch: 44\n",
            " [================================================================>]  Step: 73ms | Tot: 46s249ms | Loss: 0.313 | Acc: 89.334% (44667/50000) 391/391 \n",
            " [================================================================>]  Step: 36ms | Tot: 4s5ms | Loss: 0.457 | Acc: 84.680% (8468/10000) 100/100 \n",
            "\n",
            "Epoch: 45\n",
            " [================================================================>]  Step: 72ms | Tot: 46s439ms | Loss: 0.307 | Acc: 89.604% (44802/50000) 391/391 \n",
            " [================================================================>]  Step: 45ms | Tot: 3s967ms | Loss: 0.416 | Acc: 86.630% (8663/10000) 100/100 \n",
            "\n",
            "Epoch: 46\n",
            " [================================================================>]  Step: 82ms | Tot: 46s259ms | Loss: 0.307 | Acc: 89.574% (44787/50000) 391/391 \n",
            " [================================================================>]  Step: 41ms | Tot: 4s131ms | Loss: 0.556 | Acc: 82.070% (8207/10000) 100/100 \n",
            "\n",
            "Epoch: 47\n",
            " [================================================================>]  Step: 84ms | Tot: 46s20ms | Loss: 0.304 | Acc: 89.632% (44816/50000) 391/391 \n",
            " [================================================================>]  Step: 33ms | Tot: 4s135ms | Loss: 0.394 | Acc: 87.000% (8700/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 48\n",
            " [================================================================>]  Step: 79ms | Tot: 46s276ms | Loss: 0.305 | Acc: 89.490% (44745/50000) 391/391 \n",
            " [================================================================>]  Step: 38ms | Tot: 3s987ms | Loss: 0.499 | Acc: 84.440% (8444/10000) 100/100 \n",
            "\n",
            "Epoch: 49\n",
            " [================================================================>]  Step: 77ms | Tot: 46s353ms | Loss: 0.295 | Acc: 90.030% (45015/50000) 391/391 \n",
            " [================================================================>]  Step: 40ms | Tot: 3s927ms | Loss: 0.438 | Acc: 85.400% (8540/10000) 100/100 \n",
            "\n",
            "Epoch: 50\n",
            " [================================================================>]  Step: 82ms | Tot: 46s153ms | Loss: 0.300 | Acc: 89.730% (44865/50000) 391/391 \n",
            " [================================================================>]  Step: 33ms | Tot: 4s7ms | Loss: 0.478 | Acc: 83.910% (8391/10000) 100/100 \n",
            "\n",
            "Epoch: 51\n",
            " [================================================================>]  Step: 80ms | Tot: 45s964ms | Loss: 0.298 | Acc: 89.726% (44863/50000) 391/391 \n",
            " [================================================================>]  Step: 31ms | Tot: 4s108ms | Loss: 0.433 | Acc: 85.670% (8567/10000) 100/100 \n",
            "\n",
            "Epoch: 52\n",
            " [================================================================>]  Step: 94ms | Tot: 46s359ms | Loss: 0.294 | Acc: 90.042% (45021/50000) 391/391 \n",
            " [================================================================>]  Step: 36ms | Tot: 4s139ms | Loss: 0.391 | Acc: 87.070% (8707/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 53\n",
            " [================================================================>]  Step: 74ms | Tot: 46s124ms | Loss: 0.291 | Acc: 89.978% (44989/50000) 391/391 \n",
            " [================================================================>]  Step: 32ms | Tot: 4s73ms | Loss: 0.383 | Acc: 87.410% (8741/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 54\n",
            " [================================================================>]  Step: 83ms | Tot: 46s422ms | Loss: 0.290 | Acc: 90.140% (45070/50000) 391/391 \n",
            " [================================================================>]  Step: 44ms | Tot: 4s167ms | Loss: 0.418 | Acc: 86.240% (8624/10000) 100/100 \n",
            "\n",
            "Epoch: 55\n",
            " [================================================================>]  Step: 83ms | Tot: 46s326ms | Loss: 0.291 | Acc: 90.054% (45027/50000) 391/391 \n",
            " [================================================================>]  Step: 38ms | Tot: 4s100ms | Loss: 0.413 | Acc: 86.600% (8660/10000) 100/100 \n",
            "\n",
            "Epoch: 56\n",
            " [================================================================>]  Step: 83ms | Tot: 46s244ms | Loss: 0.283 | Acc: 90.452% (45226/50000) 391/391 \n",
            " [================================================================>]  Step: 55ms | Tot: 4s68ms | Loss: 0.337 | Acc: 88.600% (8860/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 57\n",
            " [================================================================>]  Step: 91ms | Tot: 45s963ms | Loss: 0.283 | Acc: 90.336% (45168/50000) 391/391 \n",
            " [================================================================>]  Step: 39ms | Tot: 4s69ms | Loss: 0.433 | Acc: 85.450% (8545/10000) 100/100 \n",
            "\n",
            "Epoch: 58\n",
            " [================================================================>]  Step: 84ms | Tot: 46s39ms | Loss: 0.279 | Acc: 90.584% (45292/50000) 391/391 \n",
            " [================================================================>]  Step: 48ms | Tot: 4s138ms | Loss: 0.492 | Acc: 84.700% (8470/10000) 100/100 \n",
            "\n",
            "Epoch: 59\n",
            " [================================================================>]  Step: 71ms | Tot: 46s387ms | Loss: 0.282 | Acc: 90.334% (45167/50000) 391/391 \n",
            " [================================================================>]  Step: 44ms | Tot: 4s265ms | Loss: 0.443 | Acc: 85.330% (8533/10000) 100/100 \n",
            "\n",
            "Epoch: 60\n",
            " [================================================================>]  Step: 81ms | Tot: 46s400ms | Loss: 0.278 | Acc: 90.484% (45242/50000) 391/391 \n",
            " [================================================================>]  Step: 43ms | Tot: 4s66ms | Loss: 0.498 | Acc: 83.800% (8380/10000) 100/100 \n",
            "\n",
            "Epoch: 61\n",
            " [================================================================>]  Step: 83ms | Tot: 45s983ms | Loss: 0.277 | Acc: 90.570% (45285/50000) 391/391 \n",
            " [================================================================>]  Step: 40ms | Tot: 4s30ms | Loss: 0.415 | Acc: 86.840% (8684/10000) 100/100 \n",
            "\n",
            "Epoch: 62\n",
            " [================================================================>]  Step: 82ms | Tot: 46s424ms | Loss: 0.275 | Acc: 90.634% (45317/50000) 391/391 \n",
            " [================================================================>]  Step: 28ms | Tot: 4s90ms | Loss: 0.413 | Acc: 86.270% (8627/10000) 100/100 \n",
            "\n",
            "Epoch: 63\n",
            " [================================================================>]  Step: 83ms | Tot: 46s442ms | Loss: 0.272 | Acc: 90.788% (45394/50000) 391/391 \n",
            " [================================================================>]  Step: 33ms | Tot: 4s120ms | Loss: 0.396 | Acc: 87.030% (8703/10000) 100/100 \n",
            "\n",
            "Epoch: 64\n",
            " [================================================================>]  Step: 81ms | Tot: 45s870ms | Loss: 0.271 | Acc: 90.598% (45299/50000) 391/391 \n",
            " [================================================================>]  Step: 66ms | Tot: 4s51ms | Loss: 0.381 | Acc: 87.400% (8740/10000) 100/100 \n",
            "\n",
            "Epoch: 65\n",
            " [================================================================>]  Step: 82ms | Tot: 45s937ms | Loss: 0.270 | Acc: 90.746% (45373/50000) 391/391 \n",
            " [================================================================>]  Step: 49ms | Tot: 4s47ms | Loss: 0.448 | Acc: 85.700% (8570/10000) 100/100 \n",
            "\n",
            "Epoch: 66\n",
            " [================================================================>]  Step: 81ms | Tot: 46s462ms | Loss: 0.260 | Acc: 91.126% (45563/50000) 391/391 \n",
            " [================================================================>]  Step: 40ms | Tot: 4s84ms | Loss: 0.376 | Acc: 87.460% (8746/10000) 100/100 \n",
            "\n",
            "Epoch: 67\n",
            " [================================================================>]  Step: 74ms | Tot: 46s93ms | Loss: 0.259 | Acc: 91.062% (45531/50000) 391/391 \n",
            " [================================================================>]  Step: 43ms | Tot: 4s101ms | Loss: 0.451 | Acc: 85.210% (8521/10000) 100/100 \n",
            "\n",
            "Epoch: 68\n",
            " [================================================================>]  Step: 74ms | Tot: 46s38ms | Loss: 0.267 | Acc: 90.944% (45472/50000) 391/391 \n",
            " [================================================================>]  Step: 34ms | Tot: 4s76ms | Loss: 0.388 | Acc: 87.170% (8717/10000) 100/100 \n",
            "\n",
            "Epoch: 69\n",
            " [================================================================>]  Step: 77ms | Tot: 46s270ms | Loss: 0.260 | Acc: 91.122% (45561/50000) 391/391 \n",
            " [================================================================>]  Step: 46ms | Tot: 4s140ms | Loss: 0.446 | Acc: 85.320% (8532/10000) 100/100 \n",
            "\n",
            "Epoch: 70\n",
            " [================================================================>]  Step: 78ms | Tot: 46s115ms | Loss: 0.259 | Acc: 91.152% (45576/50000) 391/391 \n",
            " [================================================================>]  Step: 33ms | Tot: 4s186ms | Loss: 0.453 | Acc: 85.840% (8584/10000) 100/100 \n",
            "\n",
            "Epoch: 71\n",
            " [================================================================>]  Step: 78ms | Tot: 46s204ms | Loss: 0.255 | Acc: 91.402% (45701/50000) 391/391 \n",
            " [================================================================>]  Step: 41ms | Tot: 4s922ms | Loss: 0.501 | Acc: 84.340% (8434/10000) 100/100 \n",
            "\n",
            "Epoch: 72\n",
            " [================================================================>]  Step: 75ms | Tot: 46s101ms | Loss: 0.257 | Acc: 91.236% (45618/50000) 391/391 \n",
            " [================================================================>]  Step: 30ms | Tot: 4s76ms | Loss: 0.438 | Acc: 85.980% (8598/10000) 100/100 \n",
            "\n",
            "Epoch: 73\n",
            " [================================================================>]  Step: 72ms | Tot: 46s481ms | Loss: 0.253 | Acc: 91.360% (45680/50000) 391/391 \n",
            " [================================================================>]  Step: 42ms | Tot: 4s108ms | Loss: 0.407 | Acc: 86.680% (8668/10000) 100/100 \n",
            "\n",
            "Epoch: 74\n",
            " [================================================================>]  Step: 76ms | Tot: 46s274ms | Loss: 0.253 | Acc: 91.324% (45662/50000) 391/391 \n",
            " [================================================================>]  Step: 35ms | Tot: 4s264ms | Loss: 0.495 | Acc: 84.010% (8401/10000) 100/100 \n",
            "\n",
            "Epoch: 75\n",
            " [================================================================>]  Step: 81ms | Tot: 46s359ms | Loss: 0.254 | Acc: 91.184% (45592/50000) 391/391 \n",
            " [================================================================>]  Step: 40ms | Tot: 4s27ms | Loss: 0.450 | Acc: 85.230% (8523/10000) 100/100 \n",
            "\n",
            "Epoch: 76\n",
            " [================================================================>]  Step: 74ms | Tot: 46s134ms | Loss: 0.247 | Acc: 91.588% (45794/50000) 391/391 \n",
            " [================================================================>]  Step: 47ms | Tot: 4s180ms | Loss: 0.394 | Acc: 87.510% (8751/10000) 100/100 \n",
            "\n",
            "Epoch: 77\n",
            " [================================================================>]  Step: 75ms | Tot: 45s878ms | Loss: 0.239 | Acc: 91.916% (45958/50000) 391/391 \n",
            " [================================================================>]  Step: 42ms | Tot: 4s112ms | Loss: 0.419 | Acc: 86.940% (8694/10000) 100/100 \n",
            "\n",
            "Epoch: 78\n",
            " [================================================================>]  Step: 79ms | Tot: 46s134ms | Loss: 0.246 | Acc: 91.664% (45832/50000) 391/391 \n",
            " [================================================================>]  Step: 30ms | Tot: 4s377ms | Loss: 0.364 | Acc: 87.870% (8787/10000) 100/100 \n",
            "\n",
            "Epoch: 79\n",
            " [================================================================>]  Step: 82ms | Tot: 45s696ms | Loss: 0.240 | Acc: 91.786% (45893/50000) 391/391 \n",
            " [================================================================>]  Step: 42ms | Tot: 4s55ms | Loss: 0.391 | Acc: 87.430% (8743/10000) 100/100 \n",
            "\n",
            "Epoch: 80\n",
            " [================================================================>]  Step: 90ms | Tot: 45s818ms | Loss: 0.235 | Acc: 92.014% (46007/50000) 391/391 \n",
            " [================================================================>]  Step: 47ms | Tot: 3s998ms | Loss: 0.444 | Acc: 85.630% (8563/10000) 100/100 \n",
            "\n",
            "Epoch: 81\n",
            " [================================================================>]  Step: 80ms | Tot: 46s28ms | Loss: 0.238 | Acc: 91.730% (45865/50000) 391/391 \n",
            " [================================================================>]  Step: 41ms | Tot: 4s119ms | Loss: 0.354 | Acc: 88.070% (8807/10000) 100/100 \n",
            "\n",
            "Epoch: 82\n",
            " [================================================================>]  Step: 77ms | Tot: 46s174ms | Loss: 0.233 | Acc: 91.924% (45962/50000) 391/391 \n",
            " [================================================================>]  Step: 34ms | Tot: 4s87ms | Loss: 0.371 | Acc: 87.830% (8783/10000) 100/100 \n",
            "\n",
            "Epoch: 83\n",
            " [================================================================>]  Step: 75ms | Tot: 45s775ms | Loss: 0.232 | Acc: 92.072% (46036/50000) 391/391 \n",
            " [================================================================>]  Step: 36ms | Tot: 4s37ms | Loss: 0.391 | Acc: 86.730% (8673/10000) 100/100 \n",
            "\n",
            "Epoch: 84\n",
            " [================================================================>]  Step: 80ms | Tot: 46s265ms | Loss: 0.231 | Acc: 92.174% (46087/50000) 391/391 \n",
            " [================================================================>]  Step: 37ms | Tot: 3s914ms | Loss: 0.429 | Acc: 86.040% (8604/10000) 100/100 \n",
            "\n",
            "Epoch: 85\n",
            " [================================================================>]  Step: 83ms | Tot: 45s867ms | Loss: 0.228 | Acc: 92.216% (46108/50000) 391/391 \n",
            " [================================================================>]  Step: 42ms | Tot: 4s207ms | Loss: 0.408 | Acc: 86.810% (8681/10000) 100/100 \n",
            "\n",
            "Epoch: 86\n",
            " [================================================================>]  Step: 86ms | Tot: 45s953ms | Loss: 0.223 | Acc: 92.422% (46211/50000) 391/391 \n",
            " [================================================================>]  Step: 40ms | Tot: 4s85ms | Loss: 0.372 | Acc: 88.040% (8804/10000) 100/100 \n",
            "\n",
            "Epoch: 87\n",
            " [================================================================>]  Step: 79ms | Tot: 46s276ms | Loss: 0.224 | Acc: 92.338% (46169/50000) 391/391 \n",
            " [================================================================>]  Step: 39ms | Tot: 3s959ms | Loss: 0.353 | Acc: 88.420% (8842/10000) 100/100 \n",
            "\n",
            "Epoch: 88\n",
            " [================================================================>]  Step: 84ms | Tot: 46s301ms | Loss: 0.219 | Acc: 92.418% (46209/50000) 391/391 \n",
            " [================================================================>]  Step: 31ms | Tot: 3s927ms | Loss: 0.347 | Acc: 88.760% (8876/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 89\n",
            " [================================================================>]  Step: 76ms | Tot: 46s39ms | Loss: 0.213 | Acc: 92.714% (46357/50000) 391/391 \n",
            " [================================================================>]  Step: 36ms | Tot: 4s20ms | Loss: 0.322 | Acc: 89.620% (8962/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 90\n",
            " [================================================================>]  Step: 76ms | Tot: 46s203ms | Loss: 0.211 | Acc: 92.848% (46424/50000) 391/391 \n",
            " [================================================================>]  Step: 32ms | Tot: 4s277ms | Loss: 0.396 | Acc: 86.910% (8691/10000) 100/100 \n",
            "\n",
            "Epoch: 91\n",
            " [================================================================>]  Step: 81ms | Tot: 46s460ms | Loss: 0.215 | Acc: 92.704% (46352/50000) 391/391 \n",
            " [================================================================>]  Step: 30ms | Tot: 4s246ms | Loss: 0.323 | Acc: 89.540% (8954/10000) 100/100 \n",
            "\n",
            "Epoch: 92\n",
            " [================================================================>]  Step: 83ms | Tot: 45s951ms | Loss: 0.203 | Acc: 93.056% (46528/50000) 391/391 \n",
            " [================================================================>]  Step: 36ms | Tot: 4s111ms | Loss: 0.352 | Acc: 88.020% (8802/10000) 100/100 \n",
            "\n",
            "Epoch: 93\n",
            " [================================================================>]  Step: 85ms | Tot: 46s326ms | Loss: 0.207 | Acc: 93.078% (46539/50000) 391/391 \n",
            " [================================================================>]  Step: 43ms | Tot: 4s139ms | Loss: 0.367 | Acc: 88.010% (8801/10000) 100/100 \n",
            "\n",
            "Epoch: 94\n",
            " [================================================================>]  Step: 75ms | Tot: 46s178ms | Loss: 0.205 | Acc: 92.986% (46493/50000) 391/391 \n",
            " [================================================================>]  Step: 41ms | Tot: 4s183ms | Loss: 0.408 | Acc: 86.730% (8673/10000) 100/100 \n",
            "\n",
            "Epoch: 95\n",
            " [================================================================>]  Step: 85ms | Tot: 46s455ms | Loss: 0.200 | Acc: 93.188% (46594/50000) 391/391 \n",
            " [================================================================>]  Step: 43ms | Tot: 4s140ms | Loss: 0.353 | Acc: 88.810% (8881/10000) 100/100 \n",
            "\n",
            "Epoch: 96\n",
            " [================================================================>]  Step: 84ms | Tot: 46s515ms | Loss: 0.200 | Acc: 93.122% (46561/50000) 391/391 \n",
            " [================================================================>]  Step: 33ms | Tot: 4s160ms | Loss: 0.347 | Acc: 88.990% (8899/10000) 100/100 \n",
            "\n",
            "Epoch: 97\n",
            " [================================================================>]  Step: 83ms | Tot: 46s385ms | Loss: 0.194 | Acc: 93.428% (46714/50000) 391/391 \n",
            " [================================================================>]  Step: 38ms | Tot: 4s179ms | Loss: 0.378 | Acc: 88.050% (8805/10000) 100/100 \n",
            "\n",
            "Epoch: 98\n",
            " [================================================================>]  Step: 81ms | Tot: 46s377ms | Loss: 0.193 | Acc: 93.464% (46732/50000) 391/391 \n",
            " [================================================================>]  Step: 32ms | Tot: 4s90ms | Loss: 0.382 | Acc: 87.520% (8752/10000) 100/100 \n",
            "\n",
            "Epoch: 99\n",
            " [================================================================>]  Step: 76ms | Tot: 46s47ms | Loss: 0.193 | Acc: 93.356% (46678/50000) 391/391 \n",
            " [================================================================>]  Step: 35ms | Tot: 4s367ms | Loss: 0.391 | Acc: 87.030% (8703/10000) 100/100 \n",
            "\n",
            "Epoch: 100\n",
            " [================================================================>]  Step: 83ms | Tot: 46s9ms | Loss: 0.184 | Acc: 93.680% (46840/50000) 391/391 \n",
            " [================================================================>]  Step: 41ms | Tot: 4s102ms | Loss: 0.444 | Acc: 86.340% (8634/10000) 100/100 \n",
            "\n",
            "Epoch: 101\n",
            " [================================================================>]  Step: 79ms | Tot: 45s894ms | Loss: 0.182 | Acc: 93.888% (46944/50000) 391/391 \n",
            " [================================================================>]  Step: 47ms | Tot: 4s255ms | Loss: 0.363 | Acc: 88.060% (8806/10000) 100/100 \n",
            "\n",
            "Epoch: 102\n",
            " [================================================================>]  Step: 72ms | Tot: 46s262ms | Loss: 0.183 | Acc: 93.640% (46820/50000) 391/391 \n",
            " [================================================================>]  Step: 36ms | Tot: 4s126ms | Loss: 0.339 | Acc: 89.050% (8905/10000) 100/100 \n",
            "\n",
            "Epoch: 103\n",
            " [================================================================>]  Step: 77ms | Tot: 46s311ms | Loss: 0.176 | Acc: 93.972% (46986/50000) 391/391 \n",
            " [================================================================>]  Step: 49ms | Tot: 4s279ms | Loss: 0.324 | Acc: 89.400% (8940/10000) 100/100 \n",
            "\n",
            "Epoch: 104\n",
            " [================================================================>]  Step: 73ms | Tot: 46s360ms | Loss: 0.177 | Acc: 93.884% (46942/50000) 391/391 \n",
            " [================================================================>]  Step: 40ms | Tot: 4s170ms | Loss: 0.345 | Acc: 88.820% (8882/10000) 100/100 \n",
            "\n",
            "Epoch: 105\n",
            " [================================================================>]  Step: 75ms | Tot: 46s416ms | Loss: 0.176 | Acc: 93.938% (46969/50000) 391/391 \n",
            " [================================================================>]  Step: 50ms | Tot: 4s213ms | Loss: 0.329 | Acc: 89.640% (8964/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 106\n",
            " [================================================================>]  Step: 81ms | Tot: 46s504ms | Loss: 0.176 | Acc: 94.012% (47006/50000) 391/391 \n",
            " [================================================================>]  Step: 43ms | Tot: 4s162ms | Loss: 0.318 | Acc: 90.160% (9016/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 107\n",
            " [================================================================>]  Step: 78ms | Tot: 45s871ms | Loss: 0.162 | Acc: 94.492% (47246/50000) 391/391 \n",
            " [================================================================>]  Step: 37ms | Tot: 4s202ms | Loss: 0.377 | Acc: 88.180% (8818/10000) 100/100 \n",
            "\n",
            "Epoch: 108\n",
            " [================================================================>]  Step: 77ms | Tot: 46s625ms | Loss: 0.172 | Acc: 94.106% (47053/50000) 391/391 \n",
            " [================================================================>]  Step: 33ms | Tot: 4s112ms | Loss: 0.383 | Acc: 87.260% (8726/10000) 100/100 \n",
            "\n",
            "Epoch: 109\n",
            " [================================================================>]  Step: 76ms | Tot: 46s519ms | Loss: 0.162 | Acc: 94.388% (47194/50000) 391/391 \n",
            " [================================================================>]  Step: 38ms | Tot: 4s262ms | Loss: 0.305 | Acc: 90.180% (9018/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 110\n",
            " [================================================================>]  Step: 83ms | Tot: 46s97ms | Loss: 0.157 | Acc: 94.698% (47349/50000) 391/391 \n",
            " [================================================================>]  Step: 46ms | Tot: 4s109ms | Loss: 0.363 | Acc: 88.730% (8873/10000) 100/100 \n",
            "\n",
            "Epoch: 111\n",
            " [================================================================>]  Step: 80ms | Tot: 46s544ms | Loss: 0.160 | Acc: 94.552% (47276/50000) 391/391 \n",
            " [================================================================>]  Step: 51ms | Tot: 4s236ms | Loss: 0.327 | Acc: 89.410% (8941/10000) 100/100 \n",
            "\n",
            "Epoch: 112\n",
            " [================================================================>]  Step: 75ms | Tot: 46s816ms | Loss: 0.156 | Acc: 94.638% (47319/50000) 391/391 \n",
            " [================================================================>]  Step: 39ms | Tot: 4s169ms | Loss: 0.342 | Acc: 89.120% (8912/10000) 100/100 \n",
            "\n",
            "Epoch: 113\n",
            " [================================================================>]  Step: 80ms | Tot: 46s102ms | Loss: 0.152 | Acc: 94.822% (47411/50000) 391/391 \n",
            " [================================================================>]  Step: 52ms | Tot: 4s239ms | Loss: 0.282 | Acc: 91.050% (9105/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 114\n",
            " [================================================================>]  Step: 76ms | Tot: 46s362ms | Loss: 0.151 | Acc: 94.850% (47425/50000) 391/391 \n",
            " [================================================================>]  Step: 39ms | Tot: 4s52ms | Loss: 0.335 | Acc: 89.630% (8963/10000) 100/100 \n",
            "\n",
            "Epoch: 115\n",
            " [================================================================>]  Step: 80ms | Tot: 46s710ms | Loss: 0.146 | Acc: 95.034% (47517/50000) 391/391 \n",
            " [================================================================>]  Step: 45ms | Tot: 4s146ms | Loss: 0.356 | Acc: 89.010% (8901/10000) 100/100 \n",
            "\n",
            "Epoch: 116\n",
            " [================================================================>]  Step: 75ms | Tot: 46s663ms | Loss: 0.143 | Acc: 95.048% (47524/50000) 391/391 \n",
            " [================================================================>]  Step: 41ms | Tot: 4s277ms | Loss: 0.296 | Acc: 90.910% (9091/10000) 100/100 \n",
            "\n",
            "Epoch: 117\n",
            " [================================================================>]  Step: 72ms | Tot: 46s425ms | Loss: 0.138 | Acc: 95.262% (47631/50000) 391/391 \n",
            " [================================================================>]  Step: 52ms | Tot: 4s129ms | Loss: 0.317 | Acc: 90.210% (9021/10000) 100/100 \n",
            "\n",
            "Epoch: 118\n",
            " [================================================================>]  Step: 81ms | Tot: 46s710ms | Loss: 0.136 | Acc: 95.344% (47672/50000) 391/391 \n",
            " [================================================================>]  Step: 37ms | Tot: 4s183ms | Loss: 0.296 | Acc: 90.570% (9057/10000) 100/100 \n",
            "\n",
            "Epoch: 119\n",
            " [================================================================>]  Step: 84ms | Tot: 46s714ms | Loss: 0.131 | Acc: 95.526% (47763/50000) 391/391 \n",
            " [================================================================>]  Step: 38ms | Tot: 4s279ms | Loss: 0.339 | Acc: 89.200% (8920/10000) 100/100 \n",
            "\n",
            "Epoch: 120\n",
            " [================================================================>]  Step: 76ms | Tot: 46s260ms | Loss: 0.133 | Acc: 95.574% (47787/50000) 391/391 \n",
            " [================================================================>]  Step: 42ms | Tot: 4s210ms | Loss: 0.313 | Acc: 90.540% (9054/10000) 100/100 \n",
            "\n",
            "Epoch: 121\n",
            " [================================================================>]  Step: 84ms | Tot: 46s294ms | Loss: 0.127 | Acc: 95.702% (47851/50000) 391/391 \n",
            " [================================================================>]  Step: 50ms | Tot: 4s236ms | Loss: 0.324 | Acc: 89.910% (8991/10000) 100/100 \n",
            "\n",
            "Epoch: 122\n",
            " [================================================================>]  Step: 80ms | Tot: 46s334ms | Loss: 0.125 | Acc: 95.772% (47886/50000) 391/391 \n",
            " [================================================================>]  Step: 34ms | Tot: 4s313ms | Loss: 0.302 | Acc: 90.630% (9063/10000) 100/100 \n",
            "\n",
            "Epoch: 123\n",
            " [================================================================>]  Step: 88ms | Tot: 46s598ms | Loss: 0.126 | Acc: 95.660% (47830/50000) 391/391 \n",
            " [================================================================>]  Step: 41ms | Tot: 4s261ms | Loss: 0.270 | Acc: 91.290% (9129/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 124\n",
            " [================================================================>]  Step: 83ms | Tot: 46s586ms | Loss: 0.125 | Acc: 95.704% (47852/50000) 391/391 \n",
            " [================================================================>]  Step: 35ms | Tot: 4s195ms | Loss: 0.275 | Acc: 91.480% (9148/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 125\n",
            " [================================================================>]  Step: 90ms | Tot: 46s181ms | Loss: 0.120 | Acc: 95.912% (47956/50000) 391/391 \n",
            " [================================================================>]  Step: 26ms | Tot: 4s295ms | Loss: 0.305 | Acc: 90.170% (9017/10000) 100/100 \n",
            "\n",
            "Epoch: 126\n",
            " [================================================================>]  Step: 79ms | Tot: 46s438ms | Loss: 0.112 | Acc: 96.222% (48111/50000) 391/391 \n",
            " [================================================================>]  Step: 42ms | Tot: 4s159ms | Loss: 0.327 | Acc: 89.930% (8993/10000) 100/100 \n",
            "\n",
            "Epoch: 127\n",
            " [================================================================>]  Step: 86ms | Tot: 45s931ms | Loss: 0.110 | Acc: 96.286% (48143/50000) 391/391 \n",
            " [================================================================>]  Step: 41ms | Tot: 4s582ms | Loss: 0.279 | Acc: 91.250% (9125/10000) 100/100 \n",
            "\n",
            "Epoch: 128\n",
            " [================================================================>]  Step: 80ms | Tot: 46s189ms | Loss: 0.111 | Acc: 96.242% (48121/50000) 391/391 \n",
            " [================================================================>]  Step: 40ms | Tot: 4s315ms | Loss: 0.294 | Acc: 91.150% (9115/10000) 100/100 \n",
            "\n",
            "Epoch: 129\n",
            " [================================================================>]  Step: 80ms | Tot: 46s273ms | Loss: 0.105 | Acc: 96.462% (48231/50000) 391/391 \n",
            " [================================================================>]  Step: 33ms | Tot: 4s228ms | Loss: 0.310 | Acc: 90.540% (9054/10000) 100/100 \n",
            "\n",
            "Epoch: 130\n",
            " [================================================================>]  Step: 78ms | Tot: 46s760ms | Loss: 0.106 | Acc: 96.386% (48193/50000) 391/391 \n",
            " [================================================================>]  Step: 28ms | Tot: 4s135ms | Loss: 0.284 | Acc: 91.280% (9128/10000) 100/100 \n",
            "\n",
            "Epoch: 131\n",
            " [================================================================>]  Step: 68ms | Tot: 46s385ms | Loss: 0.103 | Acc: 96.516% (48258/50000) 391/391 \n",
            " [================================================================>]  Step: 46ms | Tot: 4s304ms | Loss: 0.294 | Acc: 91.200% (9120/10000) 100/100 \n",
            "\n",
            "Epoch: 132\n",
            " [================================================================>]  Step: 79ms | Tot: 46s478ms | Loss: 0.094 | Acc: 96.820% (48410/50000) 391/391 \n",
            " [================================================================>]  Step: 40ms | Tot: 4s208ms | Loss: 0.275 | Acc: 91.430% (9143/10000) 100/100 \n",
            "\n",
            "Epoch: 133\n",
            " [================================================================>]  Step: 90ms | Tot: 46s463ms | Loss: 0.091 | Acc: 96.844% (48422/50000) 391/391 \n",
            " [================================================================>]  Step: 43ms | Tot: 4s359ms | Loss: 0.268 | Acc: 91.970% (9197/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 134\n",
            " [================================================================>]  Step: 87ms | Tot: 46s295ms | Loss: 0.092 | Acc: 97.004% (48502/50000) 391/391 \n",
            " [================================================================>]  Step: 55ms | Tot: 4s668ms | Loss: 0.279 | Acc: 91.560% (9156/10000) 100/100 \n",
            "\n",
            "Epoch: 135\n",
            " [================================================================>]  Step: 78ms | Tot: 46s413ms | Loss: 0.091 | Acc: 96.920% (48460/50000) 391/391 \n",
            " [================================================================>]  Step: 40ms | Tot: 4s269ms | Loss: 0.240 | Acc: 92.620% (9262/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 136\n",
            " [================================================================>]  Step: 81ms | Tot: 46s610ms | Loss: 0.079 | Acc: 97.400% (48700/50000) 391/391 \n",
            " [================================================================>]  Step: 44ms | Tot: 4s288ms | Loss: 0.283 | Acc: 91.640% (9164/10000) 100/100 \n",
            "\n",
            "Epoch: 137\n",
            " [================================================================>]  Step: 70ms | Tot: 46s399ms | Loss: 0.077 | Acc: 97.450% (48725/50000) 391/391 \n",
            " [================================================================>]  Step: 41ms | Tot: 4s252ms | Loss: 0.297 | Acc: 91.430% (9143/10000) 100/100 \n",
            "\n",
            "Epoch: 138\n",
            " [================================================================>]  Step: 84ms | Tot: 46s177ms | Loss: 0.080 | Acc: 97.244% (48622/50000) 391/391 \n",
            " [================================================================>]  Step: 43ms | Tot: 4s133ms | Loss: 0.278 | Acc: 91.720% (9172/10000) 100/100 \n",
            "\n",
            "Epoch: 139\n",
            " [================================================================>]  Step: 87ms | Tot: 46s290ms | Loss: 0.077 | Acc: 97.416% (48708/50000) 391/391 \n",
            " [================================================================>]  Step: 28ms | Tot: 4s288ms | Loss: 0.278 | Acc: 91.840% (9184/10000) 100/100 \n",
            "\n",
            "Epoch: 140\n",
            " [================================================================>]  Step: 82ms | Tot: 46s440ms | Loss: 0.075 | Acc: 97.540% (48770/50000) 391/391 \n",
            " [================================================================>]  Step: 36ms | Tot: 4s311ms | Loss: 0.290 | Acc: 91.240% (9124/10000) 100/100 \n",
            "\n",
            "Epoch: 141\n",
            " [================================================================>]  Step: 74ms | Tot: 46s112ms | Loss: 0.071 | Acc: 97.614% (48807/50000) 391/391 \n",
            " [================================================================>]  Step: 32ms | Tot: 4s992ms | Loss: 0.275 | Acc: 91.800% (9180/10000) 100/100 \n",
            "\n",
            "Epoch: 142\n",
            " [================================================================>]  Step: 85ms | Tot: 46s263ms | Loss: 0.063 | Acc: 97.926% (48963/50000) 391/391 \n",
            " [================================================================>]  Step: 52ms | Tot: 4s193ms | Loss: 0.275 | Acc: 92.290% (9229/10000) 100/100 \n",
            "\n",
            "Epoch: 143\n",
            " [================================================================>]  Step: 86ms | Tot: 46s403ms | Loss: 0.068 | Acc: 97.684% (48842/50000) 391/391 \n",
            " [================================================================>]  Step: 35ms | Tot: 4s138ms | Loss: 0.283 | Acc: 92.000% (9200/10000) 100/100 \n",
            "\n",
            "Epoch: 144\n",
            " [================================================================>]  Step: 71ms | Tot: 46s745ms | Loss: 0.065 | Acc: 97.824% (48912/50000) 391/391 \n",
            " [================================================================>]  Step: 41ms | Tot: 4s278ms | Loss: 0.259 | Acc: 92.760% (9276/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 145\n",
            " [================================================================>]  Step: 86ms | Tot: 46s426ms | Loss: 0.059 | Acc: 98.058% (49029/50000) 391/391 \n",
            " [================================================================>]  Step: 32ms | Tot: 4s232ms | Loss: 0.291 | Acc: 91.640% (9164/10000) 100/100 \n",
            "\n",
            "Epoch: 146\n",
            " [================================================================>]  Step: 72ms | Tot: 46s558ms | Loss: 0.057 | Acc: 98.126% (49063/50000) 391/391 \n",
            " [================================================================>]  Step: 46ms | Tot: 4s114ms | Loss: 0.271 | Acc: 92.490% (9249/10000) 100/100 \n",
            "\n",
            "Epoch: 147\n",
            " [================================================================>]  Step: 83ms | Tot: 46s555ms | Loss: 0.053 | Acc: 98.320% (49160/50000) 391/391 \n",
            " [================================================================>]  Step: 41ms | Tot: 4s419ms | Loss: 0.250 | Acc: 92.900% (9290/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 148\n",
            " [================================================================>]  Step: 82ms | Tot: 46s86ms | Loss: 0.050 | Acc: 98.346% (49173/50000) 391/391 \n",
            " [================================================================>]  Step: 52ms | Tot: 4s275ms | Loss: 0.307 | Acc: 91.600% (9160/10000) 100/100 \n",
            "\n",
            "Epoch: 149\n",
            " [================================================================>]  Step: 81ms | Tot: 46s295ms | Loss: 0.048 | Acc: 98.406% (49203/50000) 391/391 \n",
            " [================================================================>]  Step: 45ms | Tot: 4s193ms | Loss: 0.239 | Acc: 93.170% (9317/10000) 100/100 \n",
            "Saving..\n"
          ]
        }
      ]
    }
  ]
}