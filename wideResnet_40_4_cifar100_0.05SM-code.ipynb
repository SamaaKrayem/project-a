{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QcnOO_6fxrdq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import sys\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HOCZxSpnIL8u"
      },
      "outputs": [],
      "source": [
        "from torch import Tensor\n",
        "from torch.nn.init import constant_, xavier_normal_, xavier_uniform_\n",
        "from torch.nn.parameter import Parameter\n",
        "import torch.autograd\n",
        "from torch import autograd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "O24O7-P4Hy5U"
      },
      "outputs": [],
      "source": [
        "sm_alpha=0.05"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bUO3mbKAHkro"
      },
      "outputs": [],
      "source": [
        "def SMrelu_forward(z: Tensor, alpha: float):\n",
        "    relu_positive = z\n",
        "    relu_zero = 0\n",
        "    relu_output = torch.where(z>0, relu_positive, relu_zero)\n",
        "    return relu_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7RVJaBM3HmMm"
      },
      "outputs": [],
      "source": [
        "class SMRELUFunction(torch.autograd.Function):\n",
        "    \n",
        "    @staticmethod\n",
        "    def forward(ctx, z: Tensor, alpha: float):\n",
        "        relu = SMrelu_forward(z, alpha) # Regular forward pass computation from before\n",
        "        ctx.save_for_backward(z)    # Tensors should be saved using this method\n",
        "        ctx.alpha = alpha           # other properties can be saved like so\n",
        "        return relu\n",
        "    \n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        z, = ctx.saved_tensors      # Validates that no in-place modifications happened on saved tensors\n",
        "        alpha = ctx.alpha\n",
        "        \n",
        "        # Calculate diagonal of d(elu(z))/dz\n",
        "        grad_positive = torch.ones_like(z)\n",
        "        grad_zero = 0\n",
        "        \n",
        "        # Note: This is not the full Jacobian, d(elu(z))/dz, it's the diagonal\n",
        "        grad_SMrelu = torch.where(z > ((-1)*alpha), grad_positive, grad_zero)\n",
        "        \n",
        "        # Gradient of the loss w.r.t. our output\n",
        "        δ_smrelu = grad_output\n",
        "        \n",
        "        # Calcualte δz = d(elu(z))/dz * δ_elu\n",
        "        # Note: elementwise multiplication equivalant to vector-Jacobian product\n",
        "        δz = grad_SMrelu * δ_smrelu\n",
        "        return δz, None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "SvX6e5mjHpQ-"
      },
      "outputs": [],
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = SMRELUFunction.apply(self.bn1(self.conv1(x)),sm_alpha)\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = SMRELUFunction.apply(out,sm_alpha)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Gxy3S8H93knC"
      },
      "outputs": [],
      "source": [
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=True)\n",
        "\n",
        "def conv_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        init.xavier_uniform_(m.weight, gain=np.sqrt(2))\n",
        "        init.constant_(m.bias, 0)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        init.constant_(m.weight, 1)\n",
        "        init.constant_(m.bias, 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JruwS1uE33u_"
      },
      "outputs": [],
      "source": [
        "class wide_basic(nn.Module):\n",
        "    def __init__(self, in_planes, planes, dropout_rate, stride=1):\n",
        "        super(wide_basic, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, padding=1, bias=True)\n",
        "        self.dropout = nn.Dropout(p=dropout_rate)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=True)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=True),\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.dropout(self.conv1(SMRELUFunction.apply(self.bn1(x),sm_alpha)))\n",
        "        out = self.conv2(SMRELUFunction.apply(self.bn2(out),sm_alpha))\n",
        "        out += self.shortcut(x)\n",
        "\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "KDMonyZ34KlW"
      },
      "outputs": [],
      "source": [
        "class Wide_ResNet(nn.Module):\n",
        "    def __init__(self, depth, widen_factor, dropout_rate, num_classes):\n",
        "        super(Wide_ResNet, self).__init__()\n",
        "        self.in_planes = 16\n",
        "\n",
        "        assert ((depth-4)%6 ==0), 'Wide-resnet depth should be 6n+4'\n",
        "        n = (depth-4)/6\n",
        "        k = widen_factor\n",
        "\n",
        "        print('| Wide-Resnet %dx%d' %(depth, k))\n",
        "        nStages = [16, 16*k, 32*k, 64*k]\n",
        "\n",
        "        self.conv1 = conv3x3(3,nStages[0])\n",
        "        self.layer1 = self._wide_layer(wide_basic, nStages[1], n, dropout_rate, stride=1)\n",
        "        self.layer2 = self._wide_layer(wide_basic, nStages[2], n, dropout_rate, stride=2)\n",
        "        self.layer3 = self._wide_layer(wide_basic, nStages[3], n, dropout_rate, stride=2)\n",
        "        self.bn1 = nn.BatchNorm2d(nStages[3], momentum=0.9)\n",
        "        self.linear = nn.Linear(nStages[3], num_classes)\n",
        "\n",
        "    def _wide_layer(self, block, planes, num_blocks, dropout_rate, stride):\n",
        "        strides = [stride] + [1]*(int(num_blocks)-1)\n",
        "        layers = []\n",
        "\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, dropout_rate, stride))\n",
        "            self.in_planes = planes\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = SMRELUFunction.apply(self.bn1(out),sm_alpha)\n",
        "        out = F.avg_pool2d(out, 8)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "juF6l_cp4N8U"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "\n",
        "TOTAL_BAR_LENGTH=65\n",
        "_, term_width = shutil.get_terminal_size()\n",
        "term_width = int(term_width)\n",
        "last_time = time.time()\n",
        "begin_time = last_time\n",
        "\n",
        "def format_time(seconds):\n",
        "    days = int(seconds / 3600/24)\n",
        "    seconds = seconds - days*3600*24\n",
        "    hours = int(seconds / 3600)\n",
        "    seconds = seconds - hours*3600\n",
        "    minutes = int(seconds / 60)\n",
        "    seconds = seconds - minutes*60\n",
        "    secondsf = int(seconds)\n",
        "    seconds = seconds - secondsf\n",
        "    millis = int(seconds*1000)\n",
        "\n",
        "    f = ''\n",
        "    i = 1\n",
        "    if days > 0:\n",
        "        f += str(days) + 'D'\n",
        "        i += 1\n",
        "    if hours > 0 and i <= 2:\n",
        "        f += str(hours) + 'h'\n",
        "        i += 1\n",
        "    if minutes > 0 and i <= 2:\n",
        "        f += str(minutes) + 'm'\n",
        "        i += 1\n",
        "    if secondsf > 0 and i <= 2:\n",
        "        f += str(secondsf) + 's'\n",
        "        i += 1\n",
        "    if millis > 0 and i <= 2:\n",
        "        f += str(millis) + 'ms'\n",
        "        i += 1\n",
        "    if f == '':\n",
        "        f = '0ms'\n",
        "    return f\n",
        "\n",
        "def progress_bar(current, total, msg=None):\n",
        "    global last_time, begin_time\n",
        "    if current == 0:\n",
        "        begin_time = time.time()  # Reset for new bar.\n",
        "\n",
        "    cur_len = int(TOTAL_BAR_LENGTH*current/total)\n",
        "    rest_len = int(TOTAL_BAR_LENGTH - cur_len) - 1\n",
        "\n",
        "    sys.stdout.write(' [')\n",
        "    for i in range(cur_len):\n",
        "        sys.stdout.write('=')\n",
        "    sys.stdout.write('>')\n",
        "    for i in range(rest_len):\n",
        "        sys.stdout.write('.')\n",
        "    sys.stdout.write(']')\n",
        "\n",
        "    cur_time = time.time()\n",
        "    step_time = cur_time - last_time\n",
        "    last_time = cur_time\n",
        "    tot_time = cur_time - begin_time\n",
        "\n",
        "    L = []\n",
        "    L.append('  Step: %s' % format_time(step_time))\n",
        "    L.append(' | Tot: %s' % format_time(tot_time))\n",
        "    if msg:\n",
        "        L.append(' | ' + msg)\n",
        "\n",
        "    msg = ''.join(L)\n",
        "    sys.stdout.write(msg)\n",
        "    for i in range(term_width-int(TOTAL_BAR_LENGTH)-len(msg)-3):\n",
        "        sys.stdout.write(' ')\n",
        "\n",
        "    # Go back to the center of the bar.\n",
        "    for i in range(term_width-int(TOTAL_BAR_LENGTH/2)+2):\n",
        "        sys.stdout.write('\\b')\n",
        "    sys.stdout.write(' %d/%d ' % (current+1, total))\n",
        "\n",
        "    if current < total-1:\n",
        "        sys.stdout.write('\\r')\n",
        "    else:\n",
        "        sys.stdout.write('\\n')\n",
        "    sys.stdout.flush()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "M1H075pA4a-z"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import argparse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "XLVs10Fp4hSW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "ae41702e4a2442448b46a172424c6010",
            "b3da6d2243ec48189969e32692179267",
            "b2ffea0de4c54633bba9169b9bcbf082",
            "43e546fcd8ae4e4b9a7ab0359502ba7e",
            "a92c6172e7e54161a985fd87a9f4479a",
            "d452c8317881463892457f0e66b20a1a",
            "fad04481e4ce4f9b87d5dcff944e73f2",
            "38256849a289429ead10e9a54e03b5af",
            "630d8fda08f34a64921ca7b4929b9a21",
            "151eff4213a04064aafe627e7ddd923e",
            "1473cbbd62844a29a771d45bfd2f9984"
          ]
        },
        "outputId": "7520ae75-f7c6-4cf0-d1a5-867f7cbfd906"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Preparing data..\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/169001437 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ae41702e4a2442448b46a172424c6010"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-100-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "parser = argparse.ArgumentParser(description='PyTorch CIFAR100 Training')\n",
        "parser.add_argument('-f')\n",
        "parser.add_argument('--lr', default=0.1, type=float, help='learning rate')\n",
        "parser.add_argument('--resume', '-r', action='store_true',\n",
        "                    help='resume from checkpoint')\n",
        "args = parser.parse_args()\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "best_acc = 0  # best test accuracy\n",
        "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
        "\n",
        "# Data\n",
        "print('==> Preparing data..')\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR100(\n",
        "    root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR100(\n",
        "    root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "xtsixP2d4mwf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61919e24-2e8c-4b30-ef5a-15c323945cdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Building model..\n",
            "| Wide-Resnet 40x4\n"
          ]
        }
      ],
      "source": [
        "print('==> Building model..')\n",
        "net = Wide_ResNet(40, 4, 0.3, 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "11IqY-1p5Ch5"
      },
      "outputs": [],
      "source": [
        "net = net.to(device)\n",
        "if device == 'cuda':\n",
        "    net = torch.nn.DataParallel(net)\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "if args.resume:\n",
        "    # Load checkpoint.\n",
        "    print('==> Resuming from checkpoint..')\n",
        "    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n",
        "    checkpoint = torch.load('./checkpoint/ckpt.pth')\n",
        "    net.load_state_dict(checkpoint['net'])\n",
        "    best_acc = checkpoint['acc']\n",
        "    start_epoch = checkpoint['epoch']\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=args.lr,\n",
        "                      momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "uzAbz7kT5HXE"
      },
      "outputs": [],
      "source": [
        "# Training\n",
        "def train(epoch):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "        progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "                     % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "FggZDbuE5Ndx"
      },
      "outputs": [],
      "source": [
        "def test(epoch):\n",
        "    global best_acc\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "                         % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "\n",
        "    # Save checkpoint.\n",
        "    acc = 100.*correct/total\n",
        "    if acc > best_acc:\n",
        "        print('Saving..')\n",
        "        state = {\n",
        "            'net': net.state_dict(),\n",
        "            'acc': acc,\n",
        "            'epoch': epoch,\n",
        "        }\n",
        "        if not os.path.isdir('checkpoint'):\n",
        "            os.mkdir('checkpoint')\n",
        "        torch.save(state, './checkpoint/ckpt.pth')\n",
        "        best_acc = acc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "M12ZaX_a5Rtg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85677932-890a-4ba8-8a77-4b6218bb406e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 0\n",
            " [================================================================>]  Step: 232ms | Tot: 26s235ms | Loss: 3.886 | Acc: 9.538% (4769/50000) 391/391 \n",
            " [================================================================>]  Step: 27ms | Tot: 2s735ms | Loss: 3.704 | Acc: 12.470% (1247/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 1\n",
            " [================================================================>]  Step: 56ms | Tot: 26s75ms | Loss: 3.225 | Acc: 20.140% (10070/50000) 391/391 \n",
            " [================================================================>]  Step: 24ms | Tot: 2s837ms | Loss: 3.587 | Acc: 18.920% (1892/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 2\n",
            " [================================================================>]  Step: 58ms | Tot: 26s172ms | Loss: 2.738 | Acc: 29.084% (14542/50000) 391/391 \n",
            " [================================================================>]  Step: 27ms | Tot: 2s762ms | Loss: 3.871 | Acc: 19.420% (1942/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 3\n",
            " [================================================================>]  Step: 52ms | Tot: 26s147ms | Loss: 2.443 | Acc: 34.792% (17396/50000) 391/391 \n",
            " [================================================================>]  Step: 27ms | Tot: 2s770ms | Loss: 3.094 | Acc: 27.060% (2706/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 4\n",
            " [================================================================>]  Step: 52ms | Tot: 26s30ms | Loss: 2.240 | Acc: 39.520% (19760/50000) 391/391 \n",
            " [================================================================>]  Step: 26ms | Tot: 2s828ms | Loss: 2.765 | Acc: 32.850% (3285/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 5\n",
            " [================================================================>]  Step: 66ms | Tot: 25s858ms | Loss: 2.091 | Acc: 42.806% (21403/50000) 391/391 \n",
            " [================================================================>]  Step: 27ms | Tot: 2s627ms | Loss: 2.955 | Acc: 32.980% (3298/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 6\n",
            " [================================================================>]  Step: 51ms | Tot: 25s775ms | Loss: 1.983 | Acc: 45.384% (22692/50000) 391/391 \n",
            " [================================================================>]  Step: 20ms | Tot: 2s622ms | Loss: 2.684 | Acc: 36.280% (3628/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 7\n",
            " [================================================================>]  Step: 55ms | Tot: 26s108ms | Loss: 1.893 | Acc: 47.526% (23763/50000) 391/391 \n",
            " [================================================================>]  Step: 30ms | Tot: 2s755ms | Loss: 2.546 | Acc: 38.630% (3863/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 8\n",
            " [================================================================>]  Step: 53ms | Tot: 26s18ms | Loss: 1.815 | Acc: 49.312% (24656/50000) 391/391 \n",
            " [================================================================>]  Step: 30ms | Tot: 2s720ms | Loss: 2.329 | Acc: 42.530% (4253/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 9\n",
            " [================================================================>]  Step: 53ms | Tot: 25s960ms | Loss: 1.745 | Acc: 50.962% (25481/50000) 391/391 \n",
            " [================================================================>]  Step: 24ms | Tot: 2s758ms | Loss: 2.502 | Acc: 40.770% (4077/10000) 100/100 \n",
            "\n",
            "Epoch: 10\n",
            " [================================================================>]  Step: 53ms | Tot: 26s113ms | Loss: 1.696 | Acc: 52.446% (26223/50000) 391/391 \n",
            " [================================================================>]  Step: 31ms | Tot: 2s799ms | Loss: 1.931 | Acc: 50.390% (5039/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 11\n",
            " [================================================================>]  Step: 57ms | Tot: 25s987ms | Loss: 1.650 | Acc: 53.394% (26697/50000) 391/391 \n",
            " [================================================================>]  Step: 24ms | Tot: 2s640ms | Loss: 2.284 | Acc: 44.870% (4487/10000) 100/100 \n",
            "\n",
            "Epoch: 12\n",
            " [================================================================>]  Step: 59ms | Tot: 26s32ms | Loss: 1.607 | Acc: 54.556% (27278/50000) 391/391 \n",
            " [================================================================>]  Step: 20ms | Tot: 2s779ms | Loss: 2.067 | Acc: 47.970% (4797/10000) 100/100 \n",
            "\n",
            "Epoch: 13\n",
            " [================================================================>]  Step: 55ms | Tot: 25s926ms | Loss: 1.567 | Acc: 55.746% (27873/50000) 391/391 \n",
            " [================================================================>]  Step: 24ms | Tot: 2s667ms | Loss: 2.032 | Acc: 48.790% (4879/10000) 100/100 \n",
            "\n",
            "Epoch: 14\n",
            " [================================================================>]  Step: 55ms | Tot: 26s67ms | Loss: 1.538 | Acc: 56.134% (28067/50000) 391/391 \n",
            " [================================================================>]  Step: 28ms | Tot: 2s728ms | Loss: 1.844 | Acc: 52.320% (5232/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 15\n",
            " [================================================================>]  Step: 60ms | Tot: 25s939ms | Loss: 1.505 | Acc: 57.568% (28784/50000) 391/391 \n",
            " [================================================================>]  Step: 29ms | Tot: 2s729ms | Loss: 1.994 | Acc: 50.230% (5023/10000) 100/100 \n",
            "\n",
            "Epoch: 16\n",
            " [================================================================>]  Step: 55ms | Tot: 26s128ms | Loss: 1.493 | Acc: 57.724% (28862/50000) 391/391 \n",
            " [================================================================>]  Step: 25ms | Tot: 2s721ms | Loss: 2.121 | Acc: 49.470% (4947/10000) 100/100 \n",
            "\n",
            "Epoch: 17\n",
            " [================================================================>]  Step: 52ms | Tot: 26s8ms | Loss: 1.454 | Acc: 58.240% (29120/50000) 391/391 \n",
            " [================================================================>]  Step: 25ms | Tot: 2s655ms | Loss: 1.944 | Acc: 51.850% (5185/10000) 100/100 \n",
            "\n",
            "Epoch: 18\n",
            " [================================================================>]  Step: 53ms | Tot: 26s45ms | Loss: 1.442 | Acc: 58.996% (29498/50000) 391/391 \n",
            " [================================================================>]  Step: 34ms | Tot: 2s689ms | Loss: 1.942 | Acc: 51.140% (5114/10000) 100/100 \n",
            "\n",
            "Epoch: 19\n",
            " [================================================================>]  Step: 57ms | Tot: 25s965ms | Loss: 1.424 | Acc: 59.444% (29722/50000) 391/391 \n",
            " [================================================================>]  Step: 34ms | Tot: 2s835ms | Loss: 2.044 | Acc: 48.950% (4895/10000) 100/100 \n",
            "\n",
            "Epoch: 20\n",
            " [================================================================>]  Step: 53ms | Tot: 26s15ms | Loss: 1.405 | Acc: 59.896% (29948/50000) 391/391 \n",
            " [================================================================>]  Step: 24ms | Tot: 2s694ms | Loss: 1.920 | Acc: 52.230% (5223/10000) 100/100 \n",
            "\n",
            "Epoch: 21\n",
            " [================================================================>]  Step: 53ms | Tot: 25s857ms | Loss: 1.383 | Acc: 60.702% (30351/50000) 391/391 \n",
            " [================================================================>]  Step: 34ms | Tot: 2s728ms | Loss: 2.264 | Acc: 46.930% (4693/10000) 100/100 \n",
            "\n",
            "Epoch: 22\n",
            " [================================================================>]  Step: 56ms | Tot: 26s28ms | Loss: 1.375 | Acc: 60.654% (30327/50000) 391/391 \n",
            " [================================================================>]  Step: 26ms | Tot: 2s818ms | Loss: 2.214 | Acc: 46.590% (4659/10000) 100/100 \n",
            "\n",
            "Epoch: 23\n",
            " [================================================================>]  Step: 54ms | Tot: 26s193ms | Loss: 1.375 | Acc: 60.492% (30246/50000) 391/391 \n",
            " [================================================================>]  Step: 31ms | Tot: 2s867ms | Loss: 1.953 | Acc: 52.260% (5226/10000) 100/100 \n",
            "\n",
            "Epoch: 24\n",
            " [================================================================>]  Step: 54ms | Tot: 26s82ms | Loss: 1.350 | Acc: 61.458% (30729/50000) 391/391 \n",
            " [================================================================>]  Step: 17ms | Tot: 2s606ms | Loss: 1.624 | Acc: 56.720% (5672/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 25\n",
            " [================================================================>]  Step: 62ms | Tot: 25s964ms | Loss: 1.348 | Acc: 61.270% (30635/50000) 391/391 \n",
            " [================================================================>]  Step: 22ms | Tot: 2s750ms | Loss: 1.884 | Acc: 51.240% (5124/10000) 100/100 \n",
            "\n",
            "Epoch: 26\n",
            " [================================================================>]  Step: 51ms | Tot: 26s29ms | Loss: 1.327 | Acc: 61.804% (30902/50000) 391/391 \n",
            " [================================================================>]  Step: 25ms | Tot: 2s629ms | Loss: 1.764 | Acc: 54.600% (5460/10000) 100/100 \n",
            "\n",
            "Epoch: 27\n",
            " [================================================================>]  Step: 59ms | Tot: 25s925ms | Loss: 1.314 | Acc: 62.346% (31173/50000) 391/391 \n",
            " [================================================================>]  Step: 27ms | Tot: 2s721ms | Loss: 1.800 | Acc: 55.760% (5576/10000) 100/100 \n",
            "\n",
            "Epoch: 28\n",
            " [================================================================>]  Step: 59ms | Tot: 25s996ms | Loss: 1.309 | Acc: 62.444% (31222/50000) 391/391 \n",
            " [================================================================>]  Step: 23ms | Tot: 2s620ms | Loss: 2.340 | Acc: 46.030% (4603/10000) 100/100 \n",
            "\n",
            "Epoch: 29\n",
            " [================================================================>]  Step: 54ms | Tot: 26s50ms | Loss: 1.307 | Acc: 62.382% (31191/50000) 391/391 \n",
            " [================================================================>]  Step: 27ms | Tot: 2s634ms | Loss: 1.835 | Acc: 53.240% (5324/10000) 100/100 \n",
            "\n",
            "Epoch: 30\n",
            " [================================================================>]  Step: 55ms | Tot: 26s59ms | Loss: 1.296 | Acc: 62.860% (31430/50000) 391/391 \n",
            " [================================================================>]  Step: 26ms | Tot: 2s700ms | Loss: 1.827 | Acc: 53.530% (5353/10000) 100/100 \n",
            "\n",
            "Epoch: 31\n",
            " [================================================================>]  Step: 56ms | Tot: 25s985ms | Loss: 1.288 | Acc: 62.850% (31425/50000) 391/391 \n",
            " [================================================================>]  Step: 28ms | Tot: 2s681ms | Loss: 2.077 | Acc: 50.670% (5067/10000) 100/100 \n",
            "\n",
            "Epoch: 32\n",
            " [================================================================>]  Step: 56ms | Tot: 26s86ms | Loss: 1.265 | Acc: 63.634% (31817/50000) 391/391 \n",
            " [================================================================>]  Step: 23ms | Tot: 2s694ms | Loss: 2.060 | Acc: 52.450% (5245/10000) 100/100 \n",
            "\n",
            "Epoch: 33\n",
            " [================================================================>]  Step: 55ms | Tot: 25s996ms | Loss: 1.273 | Acc: 63.358% (31679/50000) 391/391 \n",
            " [================================================================>]  Step: 27ms | Tot: 2s855ms | Loss: 1.994 | Acc: 52.030% (5203/10000) 100/100 \n",
            "\n",
            "Epoch: 34\n",
            " [================================================================>]  Step: 46ms | Tot: 26s57ms | Loss: 1.253 | Acc: 63.718% (31859/50000) 391/391 \n",
            " [================================================================>]  Step: 26ms | Tot: 2s763ms | Loss: 1.725 | Acc: 56.790% (5679/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 35\n",
            " [================================================================>]  Step: 47ms | Tot: 25s993ms | Loss: 1.253 | Acc: 63.702% (31851/50000) 391/391 \n",
            " [================================================================>]  Step: 25ms | Tot: 2s848ms | Loss: 1.935 | Acc: 53.310% (5331/10000) 100/100 \n",
            "\n",
            "Epoch: 36\n",
            " [================================================================>]  Step: 62ms | Tot: 26s130ms | Loss: 1.247 | Acc: 64.128% (32064/50000) 391/391 \n",
            " [================================================================>]  Step: 21ms | Tot: 2s722ms | Loss: 1.980 | Acc: 50.630% (5063/10000) 100/100 \n",
            "\n",
            "Epoch: 37\n",
            " [================================================================>]  Step: 50ms | Tot: 25s967ms | Loss: 1.230 | Acc: 64.538% (32269/50000) 391/391 \n",
            " [================================================================>]  Step: 25ms | Tot: 2s689ms | Loss: 1.654 | Acc: 55.830% (5583/10000) 100/100 \n",
            "\n",
            "Epoch: 38\n",
            " [================================================================>]  Step: 53ms | Tot: 25s780ms | Loss: 1.236 | Acc: 64.342% (32171/50000) 391/391 \n",
            " [================================================================>]  Step: 24ms | Tot: 2s852ms | Loss: 1.709 | Acc: 56.840% (5684/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 39\n",
            " [================================================================>]  Step: 56ms | Tot: 26s63ms | Loss: 1.215 | Acc: 64.986% (32493/50000) 391/391 \n",
            " [================================================================>]  Step: 29ms | Tot: 2s820ms | Loss: 1.680 | Acc: 56.940% (5694/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 40\n",
            " [================================================================>]  Step: 51ms | Tot: 26s275ms | Loss: 1.210 | Acc: 65.270% (32635/50000) 391/391 \n",
            " [================================================================>]  Step: 25ms | Tot: 2s768ms | Loss: 2.186 | Acc: 48.330% (4833/10000) 100/100 \n",
            "\n",
            "Epoch: 41\n",
            " [================================================================>]  Step: 61ms | Tot: 26s34ms | Loss: 1.208 | Acc: 65.114% (32557/50000) 391/391 \n",
            " [================================================================>]  Step: 29ms | Tot: 2s649ms | Loss: 1.724 | Acc: 57.140% (5714/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 42\n",
            " [================================================================>]  Step: 60ms | Tot: 26s24ms | Loss: 1.208 | Acc: 65.116% (32558/50000) 391/391 \n",
            " [================================================================>]  Step: 28ms | Tot: 2s773ms | Loss: 1.660 | Acc: 56.990% (5699/10000) 100/100 \n",
            "\n",
            "Epoch: 43\n",
            " [================================================================>]  Step: 55ms | Tot: 26s122ms | Loss: 1.201 | Acc: 65.260% (32630/50000) 391/391 \n",
            " [================================================================>]  Step: 33ms | Tot: 2s665ms | Loss: 1.676 | Acc: 57.740% (5774/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 44\n",
            " [================================================================>]  Step: 54ms | Tot: 26s86ms | Loss: 1.181 | Acc: 65.846% (32923/50000) 391/391 \n",
            " [================================================================>]  Step: 26ms | Tot: 2s680ms | Loss: 1.787 | Acc: 54.580% (5458/10000) 100/100 \n",
            "\n",
            "Epoch: 45\n",
            " [================================================================>]  Step: 55ms | Tot: 25s811ms | Loss: 1.190 | Acc: 65.594% (32797/50000) 391/391 \n",
            " [================================================================>]  Step: 27ms | Tot: 2s636ms | Loss: 1.920 | Acc: 54.000% (5400/10000) 100/100 \n",
            "\n",
            "Epoch: 46\n",
            " [================================================================>]  Step: 52ms | Tot: 25s989ms | Loss: 1.173 | Acc: 65.808% (32904/50000) 391/391 \n",
            " [================================================================>]  Step: 21ms | Tot: 2s696ms | Loss: 1.749 | Acc: 54.520% (5452/10000) 100/100 \n",
            "\n",
            "Epoch: 47\n",
            " [================================================================>]  Step: 52ms | Tot: 26s71ms | Loss: 1.174 | Acc: 66.094% (33047/50000) 391/391 \n",
            " [================================================================>]  Step: 29ms | Tot: 2s763ms | Loss: 1.738 | Acc: 56.980% (5698/10000) 100/100 \n",
            "\n",
            "Epoch: 48\n",
            " [================================================================>]  Step: 51ms | Tot: 25s962ms | Loss: 1.164 | Acc: 66.136% (33068/50000) 391/391 \n",
            " [================================================================>]  Step: 21ms | Tot: 2s644ms | Loss: 1.788 | Acc: 56.270% (5627/10000) 100/100 \n",
            "\n",
            "Epoch: 49\n",
            " [================================================================>]  Step: 54ms | Tot: 26s70ms | Loss: 1.146 | Acc: 66.712% (33356/50000) 391/391 \n",
            " [================================================================>]  Step: 31ms | Tot: 2s941ms | Loss: 1.714 | Acc: 57.300% (5730/10000) 100/100 \n",
            "\n",
            "Epoch: 50\n",
            " [================================================================>]  Step: 51ms | Tot: 26s47ms | Loss: 1.159 | Acc: 66.262% (33131/50000) 391/391 \n",
            " [================================================================>]  Step: 24ms | Tot: 2s629ms | Loss: 1.839 | Acc: 55.680% (5568/10000) 100/100 \n",
            "\n",
            "Epoch: 51\n",
            " [================================================================>]  Step: 62ms | Tot: 26s176ms | Loss: 1.148 | Acc: 66.576% (33288/50000) 391/391 \n",
            " [================================================================>]  Step: 31ms | Tot: 2s790ms | Loss: 1.673 | Acc: 57.180% (5718/10000) 100/100 \n",
            "\n",
            "Epoch: 52\n",
            " [================================================================>]  Step: 62ms | Tot: 26s86ms | Loss: 1.133 | Acc: 67.062% (33531/50000) 391/391 \n",
            " [================================================================>]  Step: 28ms | Tot: 2s840ms | Loss: 1.494 | Acc: 60.340% (6034/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 53\n",
            " [================================================================>]  Step: 56ms | Tot: 26s150ms | Loss: 1.133 | Acc: 66.906% (33453/50000) 391/391 \n",
            " [================================================================>]  Step: 32ms | Tot: 2s774ms | Loss: 1.837 | Acc: 54.680% (5468/10000) 100/100 \n",
            "\n",
            "Epoch: 54\n",
            " [================================================================>]  Step: 57ms | Tot: 26s80ms | Loss: 1.128 | Acc: 67.200% (33600/50000) 391/391 \n",
            " [================================================================>]  Step: 21ms | Tot: 2s805ms | Loss: 1.724 | Acc: 57.510% (5751/10000) 100/100 \n",
            "\n",
            "Epoch: 55\n",
            " [================================================================>]  Step: 58ms | Tot: 26s2ms | Loss: 1.119 | Acc: 67.446% (33723/50000) 391/391 \n",
            " [================================================================>]  Step: 28ms | Tot: 2s631ms | Loss: 1.551 | Acc: 59.360% (5936/10000) 100/100 \n",
            "\n",
            "Epoch: 56\n",
            " [================================================================>]  Step: 55ms | Tot: 25s996ms | Loss: 1.109 | Acc: 67.638% (33819/50000) 391/391 \n",
            " [================================================================>]  Step: 28ms | Tot: 2s643ms | Loss: 1.496 | Acc: 60.690% (6069/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 57\n",
            " [================================================================>]  Step: 52ms | Tot: 26s73ms | Loss: 1.105 | Acc: 67.712% (33856/50000) 391/391 \n",
            " [================================================================>]  Step: 25ms | Tot: 2s712ms | Loss: 1.530 | Acc: 60.580% (6058/10000) 100/100 \n",
            "\n",
            "Epoch: 58\n",
            " [================================================================>]  Step: 58ms | Tot: 26s200ms | Loss: 1.098 | Acc: 68.090% (34045/50000) 391/391 \n",
            " [================================================================>]  Step: 23ms | Tot: 2s799ms | Loss: 1.570 | Acc: 59.950% (5995/10000) 100/100 \n",
            "\n",
            "Epoch: 59\n",
            " [================================================================>]  Step: 63ms | Tot: 25s968ms | Loss: 1.098 | Acc: 68.078% (34039/50000) 391/391 \n",
            " [================================================================>]  Step: 30ms | Tot: 2s817ms | Loss: 1.860 | Acc: 56.430% (5643/10000) 100/100 \n",
            "\n",
            "Epoch: 60\n",
            " [================================================================>]  Step: 62ms | Tot: 26s53ms | Loss: 1.079 | Acc: 68.418% (34209/50000) 391/391 \n",
            " [================================================================>]  Step: 26ms | Tot: 2s721ms | Loss: 1.751 | Acc: 57.300% (5730/10000) 100/100 \n",
            "\n",
            "Epoch: 61\n",
            " [================================================================>]  Step: 58ms | Tot: 26s71ms | Loss: 1.089 | Acc: 68.182% (34091/50000) 391/391 \n",
            " [================================================================>]  Step: 28ms | Tot: 2s647ms | Loss: 1.755 | Acc: 57.800% (5780/10000) 100/100 \n",
            "\n",
            "Epoch: 62\n",
            " [================================================================>]  Step: 54ms | Tot: 26s293ms | Loss: 1.072 | Acc: 68.586% (34293/50000) 391/391 \n",
            " [================================================================>]  Step: 24ms | Tot: 2s753ms | Loss: 1.689 | Acc: 58.880% (5888/10000) 100/100 \n",
            "\n",
            "Epoch: 63\n",
            " [================================================================>]  Step: 52ms | Tot: 26s143ms | Loss: 1.064 | Acc: 69.024% (34512/50000) 391/391 \n",
            " [================================================================>]  Step: 30ms | Tot: 2s771ms | Loss: 1.499 | Acc: 60.850% (6085/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 64\n",
            " [================================================================>]  Step: 59ms | Tot: 26s122ms | Loss: 1.067 | Acc: 68.896% (34448/50000) 391/391 \n",
            " [================================================================>]  Step: 26ms | Tot: 2s653ms | Loss: 1.669 | Acc: 60.370% (6037/10000) 100/100 \n",
            "\n",
            "Epoch: 65\n",
            " [================================================================>]  Step: 60ms | Tot: 25s968ms | Loss: 1.059 | Acc: 68.968% (34484/50000) 391/391 \n",
            " [================================================================>]  Step: 21ms | Tot: 2s797ms | Loss: 1.636 | Acc: 58.820% (5882/10000) 100/100 \n",
            "\n",
            "Epoch: 66\n",
            " [================================================================>]  Step: 50ms | Tot: 26s190ms | Loss: 1.042 | Acc: 69.594% (34797/50000) 391/391 \n",
            " [================================================================>]  Step: 28ms | Tot: 2s718ms | Loss: 1.952 | Acc: 54.900% (5490/10000) 100/100 \n",
            "\n",
            "Epoch: 67\n",
            " [================================================================>]  Step: 57ms | Tot: 26s182ms | Loss: 1.046 | Acc: 69.270% (34635/50000) 391/391 \n",
            " [================================================================>]  Step: 21ms | Tot: 2s870ms | Loss: 1.742 | Acc: 56.580% (5658/10000) 100/100 \n",
            "\n",
            "Epoch: 68\n",
            " [================================================================>]  Step: 59ms | Tot: 26s123ms | Loss: 1.029 | Acc: 69.984% (34992/50000) 391/391 \n",
            " [================================================================>]  Step: 25ms | Tot: 2s657ms | Loss: 1.490 | Acc: 62.690% (6269/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 69\n",
            " [================================================================>]  Step: 53ms | Tot: 26s9ms | Loss: 1.022 | Acc: 70.018% (35009/50000) 391/391 \n",
            " [================================================================>]  Step: 23ms | Tot: 2s885ms | Loss: 1.556 | Acc: 61.700% (6170/10000) 100/100 \n",
            "\n",
            "Epoch: 70\n",
            " [================================================================>]  Step: 58ms | Tot: 26s188ms | Loss: 1.021 | Acc: 70.086% (35043/50000) 391/391 \n",
            " [================================================================>]  Step: 27ms | Tot: 2s800ms | Loss: 1.431 | Acc: 63.340% (6334/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 71\n",
            " [================================================================>]  Step: 58ms | Tot: 26s119ms | Loss: 1.009 | Acc: 70.410% (35205/50000) 391/391 \n",
            " [================================================================>]  Step: 22ms | Tot: 2s748ms | Loss: 1.673 | Acc: 59.400% (5940/10000) 100/100 \n",
            "\n",
            "Epoch: 72\n",
            " [================================================================>]  Step: 64ms | Tot: 26s23ms | Loss: 1.017 | Acc: 69.978% (34989/50000) 391/391 \n",
            " [================================================================>]  Step: 23ms | Tot: 2s791ms | Loss: 1.793 | Acc: 57.480% (5748/10000) 100/100 \n",
            "\n",
            "Epoch: 73\n",
            " [================================================================>]  Step: 52ms | Tot: 25s940ms | Loss: 0.992 | Acc: 70.620% (35310/50000) 391/391 \n",
            " [================================================================>]  Step: 25ms | Tot: 2s794ms | Loss: 1.738 | Acc: 59.340% (5934/10000) 100/100 \n",
            "\n",
            "Epoch: 74\n",
            " [================================================================>]  Step: 46ms | Tot: 26s52ms | Loss: 0.997 | Acc: 70.590% (35295/50000) 391/391 \n",
            " [================================================================>]  Step: 34ms | Tot: 2s647ms | Loss: 1.710 | Acc: 60.090% (6009/10000) 100/100 \n",
            "\n",
            "Epoch: 75\n",
            " [================================================================>]  Step: 56ms | Tot: 26s158ms | Loss: 0.992 | Acc: 70.676% (35338/50000) 391/391 \n",
            " [================================================================>]  Step: 25ms | Tot: 2s772ms | Loss: 1.472 | Acc: 62.600% (6260/10000) 100/100 \n",
            "\n",
            "Epoch: 76\n",
            " [================================================================>]  Step: 60ms | Tot: 26s209ms | Loss: 0.980 | Acc: 71.188% (35594/50000) 391/391 \n",
            " [================================================================>]  Step: 24ms | Tot: 2s648ms | Loss: 1.579 | Acc: 60.980% (6098/10000) 100/100 \n",
            "\n",
            "Epoch: 77\n",
            " [================================================================>]  Step: 57ms | Tot: 26s149ms | Loss: 0.972 | Acc: 71.374% (35687/50000) 391/391 \n",
            " [================================================================>]  Step: 27ms | Tot: 2s753ms | Loss: 1.598 | Acc: 59.670% (5967/10000) 100/100 \n",
            "\n",
            "Epoch: 78\n",
            " [================================================================>]  Step: 49ms | Tot: 25s976ms | Loss: 0.971 | Acc: 71.258% (35629/50000) 391/391 \n",
            " [================================================================>]  Step: 23ms | Tot: 2s875ms | Loss: 1.787 | Acc: 57.390% (5739/10000) 100/100 \n",
            "\n",
            "Epoch: 79\n",
            " [================================================================>]  Step: 56ms | Tot: 26s36ms | Loss: 0.955 | Acc: 71.710% (35855/50000) 391/391 \n",
            " [================================================================>]  Step: 22ms | Tot: 2s733ms | Loss: 1.567 | Acc: 61.290% (6129/10000) 100/100 \n",
            "\n",
            "Epoch: 80\n",
            " [================================================================>]  Step: 63ms | Tot: 25s986ms | Loss: 0.952 | Acc: 71.850% (35925/50000) 391/391 \n",
            " [================================================================>]  Step: 28ms | Tot: 2s802ms | Loss: 1.715 | Acc: 59.520% (5952/10000) 100/100 \n",
            "\n",
            "Epoch: 81\n",
            " [================================================================>]  Step: 56ms | Tot: 26s87ms | Loss: 0.947 | Acc: 71.876% (35938/50000) 391/391 \n",
            " [================================================================>]  Step: 27ms | Tot: 2s814ms | Loss: 1.541 | Acc: 62.620% (6262/10000) 100/100 \n",
            "\n",
            "Epoch: 82\n",
            " [================================================================>]  Step: 56ms | Tot: 26s173ms | Loss: 0.931 | Acc: 72.482% (36241/50000) 391/391 \n",
            " [================================================================>]  Step: 28ms | Tot: 2s840ms | Loss: 1.602 | Acc: 60.960% (6096/10000) 100/100 \n",
            "\n",
            "Epoch: 83\n",
            " [================================================================>]  Step: 59ms | Tot: 26s224ms | Loss: 0.931 | Acc: 72.406% (36203/50000) 391/391 \n",
            " [================================================================>]  Step: 25ms | Tot: 2s722ms | Loss: 1.595 | Acc: 61.170% (6117/10000) 100/100 \n",
            "\n",
            "Epoch: 84\n",
            " [================================================================>]  Step: 60ms | Tot: 26s107ms | Loss: 0.916 | Acc: 72.900% (36450/50000) 391/391 \n",
            " [================================================================>]  Step: 20ms | Tot: 2s706ms | Loss: 1.492 | Acc: 62.010% (6201/10000) 100/100 \n",
            "\n",
            "Epoch: 85\n",
            " [================================================================>]  Step: 56ms | Tot: 26s27ms | Loss: 0.914 | Acc: 72.894% (36447/50000) 391/391 \n",
            " [================================================================>]  Step: 23ms | Tot: 2s749ms | Loss: 1.557 | Acc: 63.350% (6335/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 86\n",
            " [================================================================>]  Step: 51ms | Tot: 26s40ms | Loss: 0.904 | Acc: 73.376% (36688/50000) 391/391 \n",
            " [================================================================>]  Step: 33ms | Tot: 2s887ms | Loss: 1.496 | Acc: 62.090% (6209/10000) 100/100 \n",
            "\n",
            "Epoch: 87\n",
            " [================================================================>]  Step: 48ms | Tot: 26s84ms | Loss: 0.895 | Acc: 73.502% (36751/50000) 391/391 \n",
            " [================================================================>]  Step: 27ms | Tot: 2s616ms | Loss: 1.716 | Acc: 59.080% (5908/10000) 100/100 \n",
            "\n",
            "Epoch: 88\n",
            " [================================================================>]  Step: 53ms | Tot: 25s988ms | Loss: 0.892 | Acc: 73.652% (36826/50000) 391/391 \n",
            " [================================================================>]  Step: 23ms | Tot: 2s707ms | Loss: 1.819 | Acc: 57.350% (5735/10000) 100/100 \n",
            "\n",
            "Epoch: 89\n",
            " [================================================================>]  Step: 51ms | Tot: 26s72ms | Loss: 0.884 | Acc: 73.562% (36781/50000) 391/391 \n",
            " [================================================================>]  Step: 23ms | Tot: 2s838ms | Loss: 1.553 | Acc: 61.140% (6114/10000) 100/100 \n",
            "\n",
            "Epoch: 90\n",
            " [================================================================>]  Step: 60ms | Tot: 26s56ms | Loss: 0.873 | Acc: 74.000% (37000/50000) 391/391 \n",
            " [================================================================>]  Step: 30ms | Tot: 2s713ms | Loss: 1.553 | Acc: 61.640% (6164/10000) 100/100 \n",
            "\n",
            "Epoch: 91\n",
            " [================================================================>]  Step: 63ms | Tot: 25s953ms | Loss: 0.861 | Acc: 74.270% (37135/50000) 391/391 \n",
            " [================================================================>]  Step: 29ms | Tot: 2s662ms | Loss: 1.571 | Acc: 61.590% (6159/10000) 100/100 \n",
            "\n",
            "Epoch: 92\n",
            " [================================================================>]  Step: 56ms | Tot: 26s18ms | Loss: 0.858 | Acc: 74.314% (37157/50000) 391/391 \n",
            " [================================================================>]  Step: 26ms | Tot: 2s682ms | Loss: 1.622 | Acc: 61.790% (6179/10000) 100/100 \n",
            "\n",
            "Epoch: 93\n",
            " [================================================================>]  Step: 50ms | Tot: 26s158ms | Loss: 0.845 | Acc: 74.702% (37351/50000) 391/391 \n",
            " [================================================================>]  Step: 24ms | Tot: 2s719ms | Loss: 1.460 | Acc: 63.740% (6374/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 94\n",
            " [================================================================>]  Step: 55ms | Tot: 25s967ms | Loss: 0.834 | Acc: 75.188% (37594/50000) 391/391 \n",
            " [================================================================>]  Step: 22ms | Tot: 2s669ms | Loss: 1.424 | Acc: 63.880% (6388/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 95\n",
            " [================================================================>]  Step: 56ms | Tot: 25s962ms | Loss: 0.820 | Acc: 75.576% (37788/50000) 391/391 \n",
            " [================================================================>]  Step: 19ms | Tot: 2s651ms | Loss: 1.545 | Acc: 62.640% (6264/10000) 100/100 \n",
            "\n",
            "Epoch: 96\n",
            " [================================================================>]  Step: 57ms | Tot: 26s74ms | Loss: 0.826 | Acc: 75.218% (37609/50000) 391/391 \n",
            " [================================================================>]  Step: 24ms | Tot: 2s728ms | Loss: 1.403 | Acc: 66.380% (6638/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 97\n",
            " [================================================================>]  Step: 47ms | Tot: 26s20ms | Loss: 0.814 | Acc: 75.664% (37832/50000) 391/391 \n",
            " [================================================================>]  Step: 24ms | Tot: 2s844ms | Loss: 1.630 | Acc: 62.270% (6227/10000) 100/100 \n",
            "\n",
            "Epoch: 98\n",
            " [================================================================>]  Step: 56ms | Tot: 25s939ms | Loss: 0.801 | Acc: 75.972% (37986/50000) 391/391 \n",
            " [================================================================>]  Step: 24ms | Tot: 2s727ms | Loss: 1.428 | Acc: 64.310% (6431/10000) 100/100 \n",
            "\n",
            "Epoch: 99\n",
            " [================================================================>]  Step: 58ms | Tot: 25s968ms | Loss: 0.802 | Acc: 75.706% (37853/50000) 391/391 \n",
            " [================================================================>]  Step: 22ms | Tot: 2s811ms | Loss: 1.247 | Acc: 67.340% (6734/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 100\n",
            " [================================================================>]  Step: 47ms | Tot: 26s28ms | Loss: 0.786 | Acc: 76.494% (38247/50000) 391/391 \n",
            " [================================================================>]  Step: 28ms | Tot: 2s799ms | Loss: 1.357 | Acc: 64.930% (6493/10000) 100/100 \n",
            "\n",
            "Epoch: 101\n",
            " [================================================================>]  Step: 60ms | Tot: 26s100ms | Loss: 0.779 | Acc: 76.634% (38317/50000) 391/391 \n",
            " [================================================================>]  Step: 19ms | Tot: 2s838ms | Loss: 1.482 | Acc: 64.730% (6473/10000) 100/100 \n",
            "\n",
            "Epoch: 102\n",
            " [================================================================>]  Step: 58ms | Tot: 26s287ms | Loss: 0.759 | Acc: 77.076% (38538/50000) 391/391 \n",
            " [================================================================>]  Step: 33ms | Tot: 2s742ms | Loss: 1.474 | Acc: 64.370% (6437/10000) 100/100 \n",
            "\n",
            "Epoch: 103\n",
            " [================================================================>]  Step: 54ms | Tot: 26s263ms | Loss: 0.751 | Acc: 77.470% (38735/50000) 391/391 \n",
            " [================================================================>]  Step: 26ms | Tot: 2s654ms | Loss: 1.474 | Acc: 64.030% (6403/10000) 100/100 \n",
            "\n",
            "Epoch: 104\n",
            " [================================================================>]  Step: 60ms | Tot: 25s992ms | Loss: 0.743 | Acc: 77.568% (38784/50000) 391/391 \n",
            " [================================================================>]  Step: 22ms | Tot: 2s730ms | Loss: 1.504 | Acc: 64.820% (6482/10000) 100/100 \n",
            "\n",
            "Epoch: 105\n",
            " [================================================================>]  Step: 51ms | Tot: 26s142ms | Loss: 0.742 | Acc: 77.500% (38750/50000) 391/391 \n",
            " [================================================================>]  Step: 26ms | Tot: 2s899ms | Loss: 1.402 | Acc: 65.710% (6571/10000) 100/100 \n",
            "\n",
            "Epoch: 106\n",
            " [================================================================>]  Step: 54ms | Tot: 26s27ms | Loss: 0.728 | Acc: 78.070% (39035/50000) 391/391 \n",
            " [================================================================>]  Step: 32ms | Tot: 2s701ms | Loss: 1.490 | Acc: 64.100% (6410/10000) 100/100 \n",
            "\n",
            "Epoch: 107\n",
            " [================================================================>]  Step: 57ms | Tot: 26s141ms | Loss: 0.719 | Acc: 78.472% (39236/50000) 391/391 \n",
            " [================================================================>]  Step: 29ms | Tot: 2s690ms | Loss: 1.457 | Acc: 65.270% (6527/10000) 100/100 \n",
            "\n",
            "Epoch: 108\n",
            " [================================================================>]  Step: 53ms | Tot: 26s69ms | Loss: 0.693 | Acc: 78.906% (39453/50000) 391/391 \n",
            " [================================================================>]  Step: 27ms | Tot: 2s882ms | Loss: 1.353 | Acc: 66.660% (6666/10000) 100/100 \n",
            "\n",
            "Epoch: 109\n",
            " [================================================================>]  Step: 52ms | Tot: 26s152ms | Loss: 0.708 | Acc: 78.518% (39259/50000) 391/391 \n",
            " [================================================================>]  Step: 24ms | Tot: 2s737ms | Loss: 1.308 | Acc: 68.270% (6827/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 110\n",
            " [================================================================>]  Step: 50ms | Tot: 26s27ms | Loss: 0.684 | Acc: 79.150% (39575/50000) 391/391 \n",
            " [================================================================>]  Step: 35ms | Tot: 2s789ms | Loss: 1.425 | Acc: 66.490% (6649/10000) 100/100 \n",
            "\n",
            "Epoch: 111\n",
            " [================================================================>]  Step: 53ms | Tot: 26s10ms | Loss: 0.675 | Acc: 79.498% (39749/50000) 391/391 \n",
            " [================================================================>]  Step: 28ms | Tot: 2s760ms | Loss: 1.432 | Acc: 66.410% (6641/10000) 100/100 \n",
            "\n",
            "Epoch: 112\n",
            " [================================================================>]  Step: 54ms | Tot: 26s131ms | Loss: 0.659 | Acc: 80.142% (40071/50000) 391/391 \n",
            " [================================================================>]  Step: 35ms | Tot: 2s805ms | Loss: 1.598 | Acc: 63.270% (6327/10000) 100/100 \n",
            "\n",
            "Epoch: 113\n",
            " [================================================================>]  Step: 53ms | Tot: 26s209ms | Loss: 0.655 | Acc: 79.994% (39997/50000) 391/391 \n",
            " [================================================================>]  Step: 26ms | Tot: 2s785ms | Loss: 1.553 | Acc: 64.630% (6463/10000) 100/100 \n",
            "\n",
            "Epoch: 114\n",
            " [================================================================>]  Step: 48ms | Tot: 26s121ms | Loss: 0.645 | Acc: 80.306% (40153/50000) 391/391 \n",
            " [================================================================>]  Step: 28ms | Tot: 2s721ms | Loss: 1.364 | Acc: 66.450% (6645/10000) 100/100 \n",
            "\n",
            "Epoch: 115\n",
            " [================================================================>]  Step: 53ms | Tot: 26s98ms | Loss: 0.625 | Acc: 80.786% (40393/50000) 391/391 \n",
            " [================================================================>]  Step: 30ms | Tot: 2s698ms | Loss: 1.475 | Acc: 66.470% (6647/10000) 100/100 \n",
            "\n",
            "Epoch: 116\n",
            " [================================================================>]  Step: 63ms | Tot: 26s87ms | Loss: 0.615 | Acc: 81.242% (40621/50000) 391/391 \n",
            " [================================================================>]  Step: 20ms | Tot: 2s760ms | Loss: 1.608 | Acc: 63.960% (6396/10000) 100/100 \n",
            "\n",
            "Epoch: 117\n",
            " [================================================================>]  Step: 56ms | Tot: 26s156ms | Loss: 0.607 | Acc: 81.350% (40675/50000) 391/391 \n",
            " [================================================================>]  Step: 29ms | Tot: 2s896ms | Loss: 1.425 | Acc: 67.560% (6756/10000) 100/100 \n",
            "\n",
            "Epoch: 118\n",
            " [================================================================>]  Step: 60ms | Tot: 26s398ms | Loss: 0.596 | Acc: 82.102% (41051/50000) 391/391 \n",
            " [================================================================>]  Step: 21ms | Tot: 2s750ms | Loss: 1.360 | Acc: 67.650% (6765/10000) 100/100 \n",
            "\n",
            "Epoch: 119\n",
            " [================================================================>]  Step: 58ms | Tot: 26s160ms | Loss: 0.589 | Acc: 82.184% (41092/50000) 391/391 \n",
            " [================================================================>]  Step: 18ms | Tot: 2s750ms | Loss: 1.257 | Acc: 68.880% (6888/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 120\n",
            " [================================================================>]  Step: 57ms | Tot: 26s26ms | Loss: 0.579 | Acc: 82.194% (41097/50000) 391/391 \n",
            " [================================================================>]  Step: 25ms | Tot: 2s770ms | Loss: 1.447 | Acc: 66.180% (6618/10000) 100/100 \n",
            "\n",
            "Epoch: 121\n",
            " [================================================================>]  Step: 51ms | Tot: 26s185ms | Loss: 0.555 | Acc: 83.066% (41533/50000) 391/391 \n",
            " [================================================================>]  Step: 32ms | Tot: 2s798ms | Loss: 1.449 | Acc: 66.800% (6680/10000) 100/100 \n",
            "\n",
            "Epoch: 122\n",
            " [================================================================>]  Step: 62ms | Tot: 26s83ms | Loss: 0.555 | Acc: 83.064% (41532/50000) 391/391 \n",
            " [================================================================>]  Step: 26ms | Tot: 2s746ms | Loss: 1.357 | Acc: 68.200% (6820/10000) 100/100 \n",
            "\n",
            "Epoch: 123\n",
            " [================================================================>]  Step: 51ms | Tot: 26s248ms | Loss: 0.536 | Acc: 83.546% (41773/50000) 391/391 \n",
            " [================================================================>]  Step: 25ms | Tot: 2s730ms | Loss: 1.609 | Acc: 65.450% (6545/10000) 100/100 \n",
            "\n",
            "Epoch: 124\n",
            " [================================================================>]  Step: 59ms | Tot: 26s233ms | Loss: 0.532 | Acc: 83.574% (41787/50000) 391/391 \n",
            " [================================================================>]  Step: 25ms | Tot: 2s797ms | Loss: 1.379 | Acc: 68.090% (6809/10000) 100/100 \n",
            "\n",
            "Epoch: 125\n",
            " [================================================================>]  Step: 58ms | Tot: 26s156ms | Loss: 0.529 | Acc: 83.744% (41872/50000) 391/391 \n",
            " [================================================================>]  Step: 25ms | Tot: 2s714ms | Loss: 1.343 | Acc: 68.420% (6842/10000) 100/100 \n",
            "\n",
            "Epoch: 126\n",
            " [================================================================>]  Step: 68ms | Tot: 26s231ms | Loss: 0.506 | Acc: 84.450% (42225/50000) 391/391 \n",
            " [================================================================>]  Step: 20ms | Tot: 2s630ms | Loss: 1.374 | Acc: 68.740% (6874/10000) 100/100 \n",
            "\n",
            "Epoch: 127\n",
            " [================================================================>]  Step: 48ms | Tot: 26s120ms | Loss: 0.501 | Acc: 84.488% (42244/50000) 391/391 \n",
            " [================================================================>]  Step: 26ms | Tot: 2s754ms | Loss: 1.455 | Acc: 67.080% (6708/10000) 100/100 \n",
            "\n",
            "Epoch: 128\n",
            " [================================================================>]  Step: 58ms | Tot: 26s106ms | Loss: 0.491 | Acc: 85.102% (42551/50000) 391/391 \n",
            " [================================================================>]  Step: 24ms | Tot: 2s810ms | Loss: 1.451 | Acc: 67.260% (6726/10000) 100/100 \n",
            "\n",
            "Epoch: 129\n",
            " [================================================================>]  Step: 55ms | Tot: 26s231ms | Loss: 0.466 | Acc: 85.688% (42844/50000) 391/391 \n",
            " [================================================================>]  Step: 24ms | Tot: 2s677ms | Loss: 1.370 | Acc: 69.180% (6918/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 130\n",
            " [================================================================>]  Step: 51ms | Tot: 26s284ms | Loss: 0.452 | Acc: 86.070% (43035/50000) 391/391 \n",
            " [================================================================>]  Step: 31ms | Tot: 2s721ms | Loss: 1.553 | Acc: 67.310% (6731/10000) 100/100 \n",
            "\n",
            "Epoch: 131\n",
            " [================================================================>]  Step: 61ms | Tot: 26s324ms | Loss: 0.447 | Acc: 86.126% (43063/50000) 391/391 \n",
            " [================================================================>]  Step: 26ms | Tot: 2s831ms | Loss: 1.576 | Acc: 66.030% (6603/10000) 100/100 \n",
            "\n",
            "Epoch: 132\n",
            " [================================================================>]  Step: 54ms | Tot: 26s69ms | Loss: 0.432 | Acc: 86.684% (43342/50000) 391/391 \n",
            " [================================================================>]  Step: 23ms | Tot: 2s844ms | Loss: 1.520 | Acc: 67.940% (6794/10000) 100/100 \n",
            "\n",
            "Epoch: 133\n",
            " [================================================================>]  Step: 52ms | Tot: 26s130ms | Loss: 0.417 | Acc: 87.116% (43558/50000) 391/391 \n",
            " [================================================================>]  Step: 28ms | Tot: 2s747ms | Loss: 1.282 | Acc: 70.920% (7092/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 134\n",
            " [================================================================>]  Step: 57ms | Tot: 26s231ms | Loss: 0.419 | Acc: 87.180% (43590/50000) 391/391 \n",
            " [================================================================>]  Step: 29ms | Tot: 3s21ms | Loss: 1.373 | Acc: 69.670% (6967/10000) 100/100 \n",
            "\n",
            "Epoch: 135\n",
            " [================================================================>]  Step: 56ms | Tot: 26s521ms | Loss: 0.406 | Acc: 87.438% (43719/50000) 391/391 \n",
            " [================================================================>]  Step: 33ms | Tot: 2s861ms | Loss: 1.399 | Acc: 69.400% (6940/10000) 100/100 \n",
            "\n",
            "Epoch: 136\n",
            " [================================================================>]  Step: 52ms | Tot: 26s300ms | Loss: 0.380 | Acc: 88.290% (44145/50000) 391/391 \n",
            " [================================================================>]  Step: 28ms | Tot: 2s897ms | Loss: 1.486 | Acc: 68.200% (6820/10000) 100/100 \n",
            "\n",
            "Epoch: 137\n",
            " [================================================================>]  Step: 56ms | Tot: 26s295ms | Loss: 0.363 | Acc: 88.800% (44400/50000) 391/391 \n",
            " [================================================================>]  Step: 22ms | Tot: 2s801ms | Loss: 1.398 | Acc: 69.190% (6919/10000) 100/100 \n",
            "\n",
            "Epoch: 138\n",
            " [================================================================>]  Step: 49ms | Tot: 26s192ms | Loss: 0.360 | Acc: 88.898% (44449/50000) 391/391 \n",
            " [================================================================>]  Step: 31ms | Tot: 2s968ms | Loss: 1.400 | Acc: 70.020% (7002/10000) 100/100 \n",
            "\n",
            "Epoch: 139\n",
            " [================================================================>]  Step: 56ms | Tot: 26s217ms | Loss: 0.349 | Acc: 89.376% (44688/50000) 391/391 \n",
            " [================================================================>]  Step: 31ms | Tot: 2s724ms | Loss: 1.444 | Acc: 69.180% (6918/10000) 100/100 \n",
            "\n",
            "Epoch: 140\n",
            " [================================================================>]  Step: 55ms | Tot: 26s383ms | Loss: 0.336 | Acc: 89.794% (44897/50000) 391/391 \n",
            " [================================================================>]  Step: 25ms | Tot: 2s783ms | Loss: 1.468 | Acc: 68.150% (6815/10000) 100/100 \n",
            "\n",
            "Epoch: 141\n",
            " [================================================================>]  Step: 60ms | Tot: 26s314ms | Loss: 0.323 | Acc: 90.118% (45059/50000) 391/391 \n",
            " [================================================================>]  Step: 27ms | Tot: 2s936ms | Loss: 1.520 | Acc: 67.940% (6794/10000) 100/100 \n",
            "\n",
            "Epoch: 142\n",
            " [================================================================>]  Step: 58ms | Tot: 26s266ms | Loss: 0.306 | Acc: 90.600% (45300/50000) 391/391 \n",
            " [================================================================>]  Step: 27ms | Tot: 2s822ms | Loss: 1.476 | Acc: 69.260% (6926/10000) 100/100 \n",
            "\n",
            "Epoch: 143\n",
            " [================================================================>]  Step: 55ms | Tot: 26s412ms | Loss: 0.303 | Acc: 90.730% (45365/50000) 391/391 \n",
            " [================================================================>]  Step: 28ms | Tot: 2s944ms | Loss: 1.432 | Acc: 69.230% (6923/10000) 100/100 \n",
            "\n",
            "Epoch: 144\n",
            " [================================================================>]  Step: 61ms | Tot: 26s290ms | Loss: 0.283 | Acc: 91.438% (45719/50000) 391/391 \n",
            " [================================================================>]  Step: 24ms | Tot: 2s896ms | Loss: 1.412 | Acc: 70.670% (7067/10000) 100/100 \n",
            "\n",
            "Epoch: 145\n",
            " [================================================================>]  Step: 57ms | Tot: 26s339ms | Loss: 0.271 | Acc: 91.858% (45929/50000) 391/391 \n",
            " [================================================================>]  Step: 33ms | Tot: 2s815ms | Loss: 1.438 | Acc: 70.110% (7011/10000) 100/100 \n",
            "\n",
            "Epoch: 146\n",
            " [================================================================>]  Step: 57ms | Tot: 26s173ms | Loss: 0.268 | Acc: 91.896% (45948/50000) 391/391 \n",
            " [================================================================>]  Step: 29ms | Tot: 2s758ms | Loss: 1.360 | Acc: 70.890% (7089/10000) 100/100 \n",
            "\n",
            "Epoch: 147\n",
            " [================================================================>]  Step: 63ms | Tot: 26s177ms | Loss: 0.251 | Acc: 92.390% (46195/50000) 391/391 \n",
            " [================================================================>]  Step: 27ms | Tot: 2s764ms | Loss: 1.318 | Acc: 71.860% (7186/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 148\n",
            " [================================================================>]  Step: 52ms | Tot: 26s25ms | Loss: 0.233 | Acc: 93.024% (46512/50000) 391/391 \n",
            " [================================================================>]  Step: 31ms | Tot: 2s802ms | Loss: 1.520 | Acc: 69.770% (6977/10000) 100/100 \n",
            "\n",
            "Epoch: 149\n",
            " [================================================================>]  Step: 52ms | Tot: 26s326ms | Loss: 0.222 | Acc: 93.452% (46726/50000) 391/391 \n",
            " [================================================================>]  Step: 25ms | Tot: 2s650ms | Loss: 1.381 | Acc: 71.680% (7168/10000) 100/100 \n",
            "\n",
            "Epoch: 150\n",
            " [================================================================>]  Step: 59ms | Tot: 26s106ms | Loss: 0.215 | Acc: 93.648% (46824/50000) 391/391 \n",
            " [================================================================>]  Step: 19ms | Tot: 2s820ms | Loss: 1.441 | Acc: 71.590% (7159/10000) 100/100 \n",
            "\n",
            "Epoch: 151\n",
            " [================================================================>]  Step: 54ms | Tot: 26s91ms | Loss: 0.198 | Acc: 94.118% (47059/50000) 391/391 \n",
            " [================================================================>]  Step: 19ms | Tot: 2s782ms | Loss: 1.464 | Acc: 70.820% (7082/10000) 100/100 \n",
            "\n",
            "Epoch: 152\n",
            " [================================================================>]  Step: 59ms | Tot: 26s147ms | Loss: 0.189 | Acc: 94.534% (47267/50000) 391/391 \n",
            " [================================================================>]  Step: 25ms | Tot: 2s753ms | Loss: 1.502 | Acc: 70.180% (7018/10000) 100/100 \n",
            "\n",
            "Epoch: 153\n",
            " [================================================================>]  Step: 66ms | Tot: 26s143ms | Loss: 0.179 | Acc: 94.808% (47404/50000) 391/391 \n",
            " [================================================================>]  Step: 33ms | Tot: 2s800ms | Loss: 1.401 | Acc: 71.810% (7181/10000) 100/100 \n",
            "\n",
            "Epoch: 154\n",
            " [================================================================>]  Step: 46ms | Tot: 26s281ms | Loss: 0.171 | Acc: 95.066% (47533/50000) 391/391 \n",
            " [================================================================>]  Step: 23ms | Tot: 2s720ms | Loss: 1.448 | Acc: 71.450% (7145/10000) 100/100 \n",
            "\n",
            "Epoch: 155\n",
            " [================================================================>]  Step: 54ms | Tot: 26s249ms | Loss: 0.164 | Acc: 95.290% (47645/50000) 391/391 \n",
            " [================================================================>]  Step: 28ms | Tot: 2s816ms | Loss: 1.310 | Acc: 72.310% (7231/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 156\n",
            " [================================================================>]  Step: 56ms | Tot: 26s283ms | Loss: 0.147 | Acc: 95.950% (47975/50000) 391/391 \n",
            " [================================================================>]  Step: 25ms | Tot: 2s718ms | Loss: 1.332 | Acc: 72.800% (7280/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 157\n",
            " [================================================================>]  Step: 57ms | Tot: 26s277ms | Loss: 0.143 | Acc: 96.032% (48016/50000) 391/391 \n",
            " [================================================================>]  Step: 25ms | Tot: 2s773ms | Loss: 1.431 | Acc: 72.150% (7215/10000) 100/100 \n",
            "\n",
            "Epoch: 158\n",
            " [================================================================>]  Step: 54ms | Tot: 26s74ms | Loss: 0.128 | Acc: 96.600% (48300/50000) 391/391 \n",
            " [================================================================>]  Step: 30ms | Tot: 2s738ms | Loss: 1.344 | Acc: 72.800% (7280/10000) 100/100 \n",
            "\n",
            "Epoch: 159\n",
            " [================================================================>]  Step: 55ms | Tot: 26s270ms | Loss: 0.120 | Acc: 96.840% (48420/50000) 391/391 \n",
            " [================================================================>]  Step: 26ms | Tot: 2s769ms | Loss: 1.378 | Acc: 72.590% (7259/10000) 100/100 \n",
            "\n",
            "Epoch: 160\n",
            " [================================================================>]  Step: 53ms | Tot: 26s95ms | Loss: 0.111 | Acc: 97.142% (48571/50000) 391/391 \n",
            " [================================================================>]  Step: 22ms | Tot: 2s790ms | Loss: 1.372 | Acc: 73.370% (7337/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 161\n",
            " [================================================================>]  Step: 52ms | Tot: 26s249ms | Loss: 0.101 | Acc: 97.420% (48710/50000) 391/391 \n",
            " [================================================================>]  Step: 23ms | Tot: 2s831ms | Loss: 1.348 | Acc: 73.140% (7314/10000) 100/100 \n",
            "\n",
            "Epoch: 162\n",
            " [================================================================>]  Step: 56ms | Tot: 26s124ms | Loss: 0.089 | Acc: 97.762% (48881/50000) 391/391 \n",
            " [================================================================>]  Step: 21ms | Tot: 2s790ms | Loss: 1.396 | Acc: 73.160% (7316/10000) 100/100 \n",
            "\n",
            "Epoch: 163\n",
            " [================================================================>]  Step: 58ms | Tot: 26s213ms | Loss: 0.082 | Acc: 98.002% (49001/50000) 391/391 \n",
            " [================================================================>]  Step: 30ms | Tot: 2s847ms | Loss: 1.309 | Acc: 74.290% (7429/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 164\n",
            " [================================================================>]  Step: 53ms | Tot: 26s201ms | Loss: 0.077 | Acc: 98.212% (49106/50000) 391/391 \n",
            " [================================================================>]  Step: 24ms | Tot: 2s788ms | Loss: 1.388 | Acc: 73.130% (7313/10000) 100/100 \n",
            "\n",
            "Epoch: 165\n",
            " [================================================================>]  Step: 47ms | Tot: 26s303ms | Loss: 0.070 | Acc: 98.404% (49202/50000) 391/391 \n",
            " [================================================================>]  Step: 21ms | Tot: 2s844ms | Loss: 1.265 | Acc: 74.480% (7448/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 166\n",
            " [================================================================>]  Step: 56ms | Tot: 26s293ms | Loss: 0.062 | Acc: 98.674% (49337/50000) 391/391 \n",
            " [================================================================>]  Step: 24ms | Tot: 2s740ms | Loss: 1.292 | Acc: 74.660% (7466/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 167\n",
            " [================================================================>]  Step: 57ms | Tot: 26s213ms | Loss: 0.056 | Acc: 98.758% (49379/50000) 391/391 \n",
            " [================================================================>]  Step: 30ms | Tot: 2s747ms | Loss: 1.291 | Acc: 74.390% (7439/10000) 100/100 \n",
            "\n",
            "Epoch: 168\n",
            " [================================================================>]  Step: 52ms | Tot: 26s198ms | Loss: 0.049 | Acc: 99.070% (49535/50000) 391/391 \n",
            " [================================================================>]  Step: 31ms | Tot: 2s833ms | Loss: 1.332 | Acc: 74.320% (7432/10000) 100/100 \n",
            "\n",
            "Epoch: 169\n",
            " [================================================================>]  Step: 59ms | Tot: 26s110ms | Loss: 0.049 | Acc: 99.010% (49505/50000) 391/391 \n",
            " [================================================================>]  Step: 32ms | Tot: 2s802ms | Loss: 1.279 | Acc: 75.620% (7562/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 170\n",
            " [================================================================>]  Step: 60ms | Tot: 26s50ms | Loss: 0.039 | Acc: 99.270% (49635/50000) 391/391 \n",
            " [================================================================>]  Step: 23ms | Tot: 2s807ms | Loss: 1.259 | Acc: 75.540% (7554/10000) 100/100 \n",
            "\n",
            "Epoch: 171\n",
            " [================================================================>]  Step: 57ms | Tot: 26s208ms | Loss: 0.033 | Acc: 99.448% (49724/50000) 391/391 \n",
            " [================================================================>]  Step: 33ms | Tot: 2s769ms | Loss: 1.265 | Acc: 75.540% (7554/10000) 100/100 \n",
            "\n",
            "Epoch: 172\n",
            " [================================================================>]  Step: 49ms | Tot: 26s98ms | Loss: 0.030 | Acc: 99.546% (49773/50000) 391/391 \n",
            " [================================================================>]  Step: 21ms | Tot: 2s768ms | Loss: 1.248 | Acc: 75.630% (7563/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 173\n",
            " [================================================================>]  Step: 51ms | Tot: 26s157ms | Loss: 0.029 | Acc: 99.568% (49784/50000) 391/391 \n",
            " [================================================================>]  Step: 21ms | Tot: 2s612ms | Loss: 1.236 | Acc: 75.570% (7557/10000) 100/100 \n",
            "\n",
            "Epoch: 174\n",
            " [================================================================>]  Step: 60ms | Tot: 26s148ms | Loss: 0.024 | Acc: 99.654% (49827/50000) 391/391 \n",
            " [================================================================>]  Step: 34ms | Tot: 2s722ms | Loss: 1.206 | Acc: 76.320% (7632/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 175\n",
            " [================================================================>]  Step: 48ms | Tot: 26s40ms | Loss: 0.025 | Acc: 99.672% (49836/50000) 391/391 \n",
            " [================================================================>]  Step: 27ms | Tot: 2s798ms | Loss: 1.192 | Acc: 76.560% (7656/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 176\n",
            " [================================================================>]  Step: 56ms | Tot: 26s23ms | Loss: 0.022 | Acc: 99.746% (49873/50000) 391/391 \n",
            " [================================================================>]  Step: 24ms | Tot: 2s683ms | Loss: 1.213 | Acc: 76.270% (7627/10000) 100/100 \n",
            "\n",
            "Epoch: 177\n",
            " [================================================================>]  Step: 59ms | Tot: 26s160ms | Loss: 0.020 | Acc: 99.782% (49891/50000) 391/391 \n",
            " [================================================================>]  Step: 16ms | Tot: 2s796ms | Loss: 1.193 | Acc: 76.590% (7659/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 178\n",
            " [================================================================>]  Step: 54ms | Tot: 25s905ms | Loss: 0.019 | Acc: 99.764% (49882/50000) 391/391 \n",
            " [================================================================>]  Step: 25ms | Tot: 2s648ms | Loss: 1.198 | Acc: 76.700% (7670/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 179\n",
            " [================================================================>]  Step: 56ms | Tot: 25s975ms | Loss: 0.017 | Acc: 99.848% (49924/50000) 391/391 \n",
            " [================================================================>]  Step: 23ms | Tot: 2s797ms | Loss: 1.187 | Acc: 76.650% (7665/10000) 100/100 \n",
            "\n",
            "Epoch: 180\n",
            " [================================================================>]  Step: 51ms | Tot: 25s946ms | Loss: 0.016 | Acc: 99.834% (49917/50000) 391/391 \n",
            " [================================================================>]  Step: 30ms | Tot: 2s764ms | Loss: 1.205 | Acc: 76.440% (7644/10000) 100/100 \n",
            "\n",
            "Epoch: 181\n",
            " [================================================================>]  Step: 62ms | Tot: 26s85ms | Loss: 0.015 | Acc: 99.872% (49936/50000) 391/391 \n",
            " [================================================================>]  Step: 24ms | Tot: 2s669ms | Loss: 1.174 | Acc: 77.000% (7700/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 182\n",
            " [================================================================>]  Step: 55ms | Tot: 25s989ms | Loss: 0.015 | Acc: 99.868% (49934/50000) 391/391 \n",
            " [================================================================>]  Step: 26ms | Tot: 2s850ms | Loss: 1.158 | Acc: 77.330% (7733/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 183\n",
            " [================================================================>]  Step: 57ms | Tot: 26s137ms | Loss: 0.014 | Acc: 99.896% (49948/50000) 391/391 \n",
            " [================================================================>]  Step: 27ms | Tot: 2s780ms | Loss: 1.172 | Acc: 77.070% (7707/10000) 100/100 \n",
            "\n",
            "Epoch: 184\n",
            " [================================================================>]  Step: 51ms | Tot: 25s963ms | Loss: 0.013 | Acc: 99.896% (49948/50000) 391/391 \n",
            " [================================================================>]  Step: 25ms | Tot: 2s680ms | Loss: 1.196 | Acc: 76.830% (7683/10000) 100/100 \n",
            "\n",
            "Epoch: 185\n",
            " [================================================================>]  Step: 54ms | Tot: 26s166ms | Loss: 0.013 | Acc: 99.874% (49937/50000) 391/391 \n",
            " [================================================================>]  Step: 24ms | Tot: 2s943ms | Loss: 1.155 | Acc: 77.440% (7744/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 186\n",
            " [================================================================>]  Step: 57ms | Tot: 26s9ms | Loss: 0.013 | Acc: 99.886% (49943/50000) 391/391 \n",
            " [================================================================>]  Step: 26ms | Tot: 2s729ms | Loss: 1.149 | Acc: 77.150% (7715/10000) 100/100 \n",
            "\n",
            "Epoch: 187\n",
            " [================================================================>]  Step: 52ms | Tot: 26s55ms | Loss: 0.012 | Acc: 99.936% (49968/50000) 391/391 \n",
            " [================================================================>]  Step: 26ms | Tot: 2s764ms | Loss: 1.170 | Acc: 77.240% (7724/10000) 100/100 \n",
            "\n",
            "Epoch: 188\n",
            " [================================================================>]  Step: 60ms | Tot: 26s95ms | Loss: 0.011 | Acc: 99.950% (49975/50000) 391/391 \n",
            " [================================================================>]  Step: 24ms | Tot: 2s757ms | Loss: 1.193 | Acc: 77.090% (7709/10000) 100/100 \n",
            "\n",
            "Epoch: 189\n",
            " [================================================================>]  Step: 56ms | Tot: 26s2ms | Loss: 0.011 | Acc: 99.922% (49961/50000) 391/391 \n",
            " [================================================================>]  Step: 18ms | Tot: 2s824ms | Loss: 1.170 | Acc: 77.110% (7711/10000) 100/100 \n",
            "\n",
            "Epoch: 190\n",
            " [================================================================>]  Step: 53ms | Tot: 26s140ms | Loss: 0.011 | Acc: 99.912% (49956/50000) 391/391 \n",
            " [================================================================>]  Step: 24ms | Tot: 2s627ms | Loss: 1.170 | Acc: 77.320% (7732/10000) 100/100 \n",
            "\n",
            "Epoch: 191\n",
            " [================================================================>]  Step: 52ms | Tot: 26s141ms | Loss: 0.011 | Acc: 99.916% (49958/50000) 391/391 \n",
            " [================================================================>]  Step: 27ms | Tot: 2s686ms | Loss: 1.137 | Acc: 77.410% (7741/10000) 100/100 \n",
            "\n",
            "Epoch: 192\n",
            " [================================================================>]  Step: 53ms | Tot: 26s38ms | Loss: 0.011 | Acc: 99.936% (49968/50000) 391/391 \n",
            " [================================================================>]  Step: 19ms | Tot: 2s737ms | Loss: 1.157 | Acc: 77.200% (7720/10000) 100/100 \n",
            "\n",
            "Epoch: 193\n",
            " [================================================================>]  Step: 55ms | Tot: 26s130ms | Loss: 0.011 | Acc: 99.936% (49968/50000) 391/391 \n",
            " [================================================================>]  Step: 36ms | Tot: 2s774ms | Loss: 1.156 | Acc: 77.500% (7750/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 194\n",
            " [================================================================>]  Step: 48ms | Tot: 26s30ms | Loss: 0.011 | Acc: 99.942% (49971/50000) 391/391 \n",
            " [================================================================>]  Step: 24ms | Tot: 2s649ms | Loss: 1.141 | Acc: 77.360% (7736/10000) 100/100 \n",
            "\n",
            "Epoch: 195\n",
            " [================================================================>]  Step: 53ms | Tot: 26s125ms | Loss: 0.011 | Acc: 99.946% (49973/50000) 391/391 \n",
            " [================================================================>]  Step: 28ms | Tot: 2s739ms | Loss: 1.146 | Acc: 77.380% (7738/10000) 100/100 \n",
            "\n",
            "Epoch: 196\n",
            " [================================================================>]  Step: 56ms | Tot: 26s24ms | Loss: 0.011 | Acc: 99.924% (49962/50000) 391/391 \n",
            " [================================================================>]  Step: 23ms | Tot: 2s791ms | Loss: 1.172 | Acc: 77.050% (7705/10000) 100/100 \n",
            "\n",
            "Epoch: 197\n",
            " [================================================================>]  Step: 56ms | Tot: 26s274ms | Loss: 0.011 | Acc: 99.928% (49964/50000) 391/391 \n",
            " [================================================================>]  Step: 28ms | Tot: 2s794ms | Loss: 1.184 | Acc: 77.110% (7711/10000) 100/100 \n",
            "\n",
            "Epoch: 198\n",
            " [================================================================>]  Step: 56ms | Tot: 26s121ms | Loss: 0.010 | Acc: 99.938% (49969/50000) 391/391 \n",
            " [================================================================>]  Step: 17ms | Tot: 2s730ms | Loss: 1.164 | Acc: 77.220% (7722/10000) 100/100 \n",
            "\n",
            "Epoch: 199\n",
            " [================================================================>]  Step: 53ms | Tot: 26s65ms | Loss: 0.011 | Acc: 99.924% (49962/50000) 391/391 \n",
            " [================================================================>]  Step: 23ms | Tot: 2s792ms | Loss: 1.160 | Acc: 77.360% (7736/10000) 100/100 \n"
          ]
        }
      ],
      "source": [
        "for epoch in range(start_epoch, start_epoch+200):\n",
        "    train(epoch)\n",
        "    test(epoch)\n",
        "    scheduler.step()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ae41702e4a2442448b46a172424c6010": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b3da6d2243ec48189969e32692179267",
              "IPY_MODEL_b2ffea0de4c54633bba9169b9bcbf082",
              "IPY_MODEL_43e546fcd8ae4e4b9a7ab0359502ba7e"
            ],
            "layout": "IPY_MODEL_a92c6172e7e54161a985fd87a9f4479a"
          }
        },
        "b3da6d2243ec48189969e32692179267": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d452c8317881463892457f0e66b20a1a",
            "placeholder": "​",
            "style": "IPY_MODEL_fad04481e4ce4f9b87d5dcff944e73f2",
            "value": "100%"
          }
        },
        "b2ffea0de4c54633bba9169b9bcbf082": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38256849a289429ead10e9a54e03b5af",
            "max": 169001437,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_630d8fda08f34a64921ca7b4929b9a21",
            "value": 169001437
          }
        },
        "43e546fcd8ae4e4b9a7ab0359502ba7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_151eff4213a04064aafe627e7ddd923e",
            "placeholder": "​",
            "style": "IPY_MODEL_1473cbbd62844a29a771d45bfd2f9984",
            "value": " 169001437/169001437 [00:02&lt;00:00, 86486261.87it/s]"
          }
        },
        "a92c6172e7e54161a985fd87a9f4479a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d452c8317881463892457f0e66b20a1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fad04481e4ce4f9b87d5dcff944e73f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38256849a289429ead10e9a54e03b5af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "630d8fda08f34a64921ca7b4929b9a21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "151eff4213a04064aafe627e7ddd923e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1473cbbd62844a29a771d45bfd2f9984": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}